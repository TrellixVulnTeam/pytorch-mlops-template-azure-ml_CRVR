{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE OF CONTENTS:\n",
    "---\n",
    "* [General Information](#General-Information)\n",
    "* [Setup](#Setup)\n",
    "    * [Connect to Workspace](#Connect-to-Workspace)\n",
    "* [Retrieve the Registered Model](#Retrieve-the-Registered-Model)\n",
    "* [Retrieve the Registered Inference Environment](#Retrieve-the-Registered-Inference-Environment)\n",
    "* [Inference Artifacts & Configuration](#Inference-Artifacts-&-Configuration)\n",
    "* [Model Deployment (Local)](#Model-Deployment-(Local))\n",
    "    * [Initial Deployment](#Initial-Deployment)\n",
    "    * [Update Deployment](#Update-Deployment)\n",
    "    * [Webservice Testing](#Webservice-Testing)\n",
    "        * [Python SDK](#Python-SDK)\n",
    "        * [Send HTTP Request](#Send-HTTP-Request)\n",
    "* [Model Deployment (AKS Compute Target)](#Model-Deployment-(AKS-Compute-Target))\n",
    "    * [Retrieve AKS cluster](#Retrieve-AKS-cluster)\n",
    "    * [Deploy the Model as AKS Webservice](#Deploy-the-Model-as-AKS-Webservice)\n",
    "    * [Retrieve Existing Webservice](#Retrieve-Existing-Webservice)\n",
    "    * [Webservice Testing](#Webservice-Testing)\n",
    "        * [Python SDK](#Python-SDK)\n",
    "        * [Send HTTP Request](#Send-HTTP-Request)\n",
    "* [Resource Clean Up](#Resource-Clean-Up)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"none\"\n",
    "test2 = \"fowl-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n"
     ]
    }
   ],
   "source": [
    "if test:\n",
    "    print(\"YES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to create test deployments for the model that has been trained in `02_model_training`. \n",
    "\n",
    "These test deployments are manual deployments using the Azure Machine Learning (AML) Python SDK and are part of the Experimentation Stage of the MLOps process. Only after test deployments are successful should the source code for the model be promoted from the GIT develop branch to the GIT main branch (via pull request).\n",
    "\n",
    "In order to deploy models to the Sign Off Stage and eventually to the Execution Stage (production workloads), a deployment via Azure DevOps using the Kubernetes CLI (kubectl) is necessary instead. Respective Azure DevOps pipelines to deploy to the Sign Off and Execution Stages are provided as part of this project template. \n",
    "\n",
    "Manual deployments using **Model.deploy()** are therefore **only possible in the Experimentation Stage for model deployment testing** but cannot be used to deploy models to the Sign Off or Execution Stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append parent directory to sys path to be able to import created modules from src directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import uuid\n",
    "from azureml.core import Environment, Workspace\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.container_registry import RegistryIdentity\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice, AksWebservice, LocalWebservice, Webservice\n",
    "from PIL import Image\n",
    "\n",
    "# Import created modules\n",
    "from src.training.data_utils import load_data, preprocess_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to connect and communicate with the AML workspace, a workspace object needs to be instantiated using the AML Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the AML workspace\n",
    "# For alternative connection options see the aml_snippets directory\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the Registered Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the registered model from the workspace. The model registration has been done as part of `02_model_training`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model name\n",
    "model_name = \"fowl-model\"\n",
    "model = Model(workspace=ws, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the Registered Inference Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the inferencing environment from the workspace. This environment has been created as part of `00_environment_setup`. In order to get to know more about options on how to create an environment, see the aml_snippets directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the environment name\n",
    "env_name = \"pytorch-aml-env\"\n",
    "env = Environment.get(workspace=ws, name=env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Artifacts & Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A deployment folder for artifacts that are required for inference has been created (**src/deployment**).\n",
    "\n",
    "This folder contains the scoring script, called score.py, which has to be created to enable inference and is used by the web service call to show how to use the model.\n",
    "\n",
    "Two functions are required in the scoring script:\n",
    "1. an `init` function that executes once when the service starts - in this function you normally get the model from the registry and set global variables\n",
    "1. a `run(data)` function that executes each time a call is made to the service. In this function, you normally deserialize the json, run a prediction and output the predicted result.\n",
    "\n",
    "In addition, an inference configuration needs to be created which bundles the inference environment with the entry script and the source directory if multiple files are required for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Inference Config\n",
    "inference_config = InferenceConfig(# source_directory=\"../src/deployment\",\n",
    "                                   entry_script=\"../src/deployment/score.py\",\n",
    "                                   environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment (Local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section describes how a local test deployment to the AML Compute Instance can be done. This might not be suitable for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the name for the local deployment\n",
    "local_service_name = \"pytorch-fowl-local-test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Docker to deploy your model as a local web service is the most common option (cell below). The other alternative is to run your code directly by using local Python scripts (e.g. load the pytorch model file and use it for scoring). For more info on this option check [here](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-local)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model fowl-model:1 to /tmp/azureml_wt8fc3j5/fowl-model/1\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry 3d5545b15c4c49548d3823156fa90536.azurecr.io\n",
      "Logging into Docker registry 3d5545b15c4c49548d3823156fa90536.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM 3d5545b15c4c49548d3823156fa90536.azurecr.io/azureml/azureml_bb7eb2396099509d165438d9e824c159\n",
      " ---> 6c3266946691\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> aab751d98d17\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6ImJmMDg4ZjU5LWYwMTUtNDMzMi1iZDM2LTU0Yjk4OGJlN2M5MCIsInJlc291cmNlR3JvdXBOYW1lIjoiYW1sYnJpa3NlcmciLCJhY2NvdW50TmFtZSI6ImFtbGJyaWtzZXdzIiwid29ya3NwYWNlSWQiOiIzZDU1NDViMS01YzRjLTQ5NTQtOGQzOC0yMzE1NmZhOTA1MzYifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 169d447ad031\n",
      " ---> ce3aee0df0a1\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpa8p1cq4t.py' /var/azureml-app/main.py\n",
      " ---> Running in a1814f024c96\n",
      " ---> 8f0f3540170f\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 85ee7cdb92cb\n",
      " ---> 076b274bad8a\n",
      "Successfully built 076b274bad8a\n",
      "Successfully tagged pytorch-fowl-local-test:latest\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6790\n"
     ]
    }
   ],
   "source": [
    "# Create local deployment config\n",
    "local_deployment_config = LocalWebservice.deploy_configuration(port=6790)\n",
    "\n",
    "local_service = Model.deploy(workspace=ws,\n",
    "                             name=local_service_name,\n",
    "                             models=[model],\n",
    "                             inference_config=inference_config,\n",
    "                             deployment_config=local_deployment_config)\n",
    "\n",
    "local_service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the web service has been initially deployed, it's more efficient to use the update() method rather than starting from scratch. For more details about updating models check [this](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-update-web-service)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'local_service' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-08f80b7193f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Update to new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlocal_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlocal_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'local_service' is not defined"
     ]
    }
   ],
   "source": [
    "# Update to new model\n",
    "local_service.update(models=[model], inference_config=inference_config)\n",
    "local_service.wait_for_deployment(show_output=True)\n",
    "\n",
    "print(local_service.state)\n",
    "print(local_service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webservice Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the test image\n",
    "%matplotlib inline\n",
    "plt.imshow(Image.open(\"../data/fowl_data/example/example_image.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Python SDK to send input data to the service endpoint and retrieve prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot call run() when service is failed.\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Cannot call run() when service is failed.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Cannot call run() when service is failed.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-81bd30e9c27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run the service\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n\u001b[0;32m---> 71\u001b[0;31m                                           logger=module_logger)\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Cannot call run() when service is failed.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Cannot call run() when service is failed.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "# Preprocess the image\n",
    "input_data = preprocess_image(\"../data/fowl_data/example/example_image.jpg\")\n",
    "\n",
    "# Run the service\n",
    "result = local_service.run(input_data=json.dumps({\"data\": input_data.tolist()}))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send HTTP Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send an HTTP request with the Python requests library. This is an example for how any REST API POST operation can retrieve prediction results from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST to url http://localhost:6790/score\n",
      "Result: <html>\r\n",
      "<head>\r\n",
      "</head>\r\n",
      "<style type=\"text/css\" media=\"screen\">\r\n",
      "body {\r\n",
      "     margin:10px 120px;\r\n",
      "\t width: 950px;\r\n",
      "     padding:0px;\r\n",
      "     text-align:left;\r\n",
      "     background-color:#FFFFFF;\r\n",
      "\t font-family: Voltamoderntext, Arial, Verdana;\r\n",
      "\t font-color: #000000;\r\n",
      "\t font-size: 24px;\r\n",
      "\t background-image: url('data:image/gif;base64,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');\r\n",
      "\t background-repeat: repeat-y;\r\n",
      "\t background-size: 75px;\r\n",
      "\t }\r\n",
      ".title \t{\r\n",
      "\tfont-family: Arial;\r\n",
      "\tfont-weight: Bold;\r\n",
      "\tfont-size: 28px;\r\n",
      "\tline-height: 70px;\r\n",
      "\t}\r\n",
      ".reason\t{\r\n",
      "\tfont-family: Arial;\r\n",
      "\tfont-weight: Bold;\r\n",
      "\tfont-size: 40px;\r\n",
      "\tline-height: 50px;\r\n",
      "\t}\r\n",
      ".infotext\t{\r\n",
      "\tfont-family: Arial;\r\n",
      "\tfont-size: 18px;\r\n",
      "\tline-height: 24px;\r\n",
      "\t}\r\n",
      ".subheader1\t{\r\n",
      "\tfont-family: Arial;\r\n",
      "\tfont-weight: Bold;\r\n",
      "\tfont-size: 20px;\r\n",
      "\tline-height: 24px;\r\n",
      "\t}\r\n",
      ".infotextsmall\t{\r\n",
      "\tfont-family: Arial;\r\n",
      "\tfont-weight: Bold;\r\n",
      "\tfont-size: 14px;\r\n",
      "\tline-height: 20px;\r\n",
      "\t}\r\n",
      ".link\t{\r\n",
      "\tfont-family: Arial;\r\n",
      "\tfont-weight: Bold;\r\n",
      "\tfont-size: 24px;\r\n",
      "\tline-height: 30px;\r\n",
      "\t}\r\n",
      "hr.normal\t{\r\n",
      "\t\talign: left;\r\n",
      "\t\twidth: 200px\r\n",
      "\t}\r\n",
      "hr.bold\t{\r\n",
      "\tborder-top: 2px solid black;\r\n",
      "\talign: left;\r\n",
      "\tmargin-top: 20px;\r\n",
      "\tmargin-bottom: 20px;\r\n",
      "\t}\r\n",
      "a\t{\r\n",
      "\tfont-family: Arial;\r\n",
      "\tcolor: #000000;\r\n",
      "\tfont-weight: Bold;\r\n",
      "\ttext-decoration: underline;\r\n",
      "\t}\r\n",
      "table\t{\r\n",
      "\talign: left;\r\n",
      "\tfont-family: Arial;\r\n",
      "\tcolor: #000000;\r\n",
      "\t}\r\n",
      ".details-column-left\t{\r\n",
      "\talign: left;\r\n",
      "\tfont-family: Arial;\r\n",
      "\tfont-weight: Bold;\r\n",
      "\tfont-size: 12px;\r\n",
      "\t}\r\n",
      ".details-column-right\t{\r\n",
      "\talign: left;\r\n",
      "\tfont-family: Arial;\r\n",
      "\tfont-weight: Regular;\r\n",
      "\tfont-size: 12px;\r\n",
      "\t}\r\n",
      "</style>\r\n",
      "\r\n",
      "<body>\r\n",
      "<div class=\"title\">Access is denied by Novartis Policy</div>\r\n",
      "<div class=\"reason\">Requested website is <B>not categorized</b></div><br>\r\n",
      "<div class=\"subheader1\">What does it mean?</div>\r\n",
      "<div class=\"infotext\">Uncategorized websites (category: NONE) are blocked for security reasons.</div><br>\r\n",
      "<div class=\"subheader1\">What can you do?</div>\r\n",
      "<div class=\"infotext\">\r\n",
      "1. <i>Go to</i> <a href=\"https://sitereview.bluecoat.com\" target=\"_blank\"><B>Site Review website</B></a><BR>\r\n",
      "2. <i>Enter</i> website address (URL) into the field and <i>click</i> “Check Category” button<BR>\r\n",
      "3. <i>Select</i> <b>“Blue Coat ProxySG”</b> from “Filtering Service” drop-down menu<BR>\r\n",
      "4. <i>Select</i> Category which fits the website the best (or select “I don’t know”)<BR>\r\n",
      "5. <i>Type</i> your Novartis e-mail address in “Email Address” field<BR>\r\n",
      "6. <i>Provide</i> “Comments and Site Description”<BR>\r\n",
      "7. <i>Click</i> “Submit for Review”<BR><BR>\r\n",
      "From the moment you receive e-mail confirmation, the website will be available on Novartis proxy within <B>24h</B>\r\n",
      "</div>\r\n",
      "<br>\r\n",
      "<div class=\"subheader1\">Do you need more help?</div>\r\n",
      "<div class=\"infotext\">For more information regarding this message, please check our Knowledge Database: <a href=\"http://go/none\" target=\"_blank\">GO/NONE</a></div>\r\n",
      "<div class=\"infotext\">If you need help, please contact your local <a href=\"https://portal.novartis.net/sites/services/servicedetail?sid=snbs4youit5671\" target=\"_blank\">IT Service Desk</a></div>\r\n",
      "<div class=\"infotext\">Internet usage is regulated by <A href=\"http://isrm.novartis.net/IGM_Policy_Framework/Pages/Guidelines.aspx\"\r\n",
      "target=\"_blank\">Protecting Novartis information guideline document</A>.</div>\r\n",
      "<HR class=\"bold\">\r\n",
      "<div class=\"infotextsmall\">Connection Request Details</div>\r\n",
      "<TABLE>\r\n",
      "  <TR>\r\n",
      "    <TD class=\"details-column-left\">Novartis Internet Proxy:\r\n",
      "\r\n",
      "    <TD width=\"1\">&nbsp;</TD>\r\n",
      "    <TD class=\"details-column-right\">NVS-NLMS-SIS-PX02</TD></TR>\r\n",
      "  <TR>\r\n",
      "    <TD class=\"details-column-left\">Your Username:\r\n",
      "    <TD width=\"1\">&nbsp;</TD>\r\n",
      "    <TD class=\"details-column-right\"></TD></TR>\r\n",
      "  <TR>\r\n",
      "    <TD class=\"details-column-left\">Your IP Address:\r\n",
      "\r\n",
      "    <TD width=\"1\">&nbsp;</TD>\r\n",
      "    <TD class=\"details-column-right\">10.155.24.104</TD></TR>\r\n",
      "  <TR>\r\n",
      "    <TD class=\"details-column-left\">Web Page URL:\r\n",
      "    <TD width=\"1\">&nbsp;</TD>\r\n",
      "    <TD class=\"details-column-right\">http:&#x2F;&#x2F;localhost:6790&#x2F;score</TD></TR>\r\n",
      "  <TR>\r\n",
      "    <TD class=\"details-column-left\">Category:\r\n",
      "\r\n",
      "    <TD width=\"1\">&nbsp;</TD>\r\n",
      "    <TD class=\"details-column-right\">none</TD></TR>\r\n",
      "  <TR>\r\n",
      "    <TD class=\"details-column-left\">Current UTC date/time:\r\n",
      "\r\n",
      "    <TD width=\"1\">&nbsp;</TD>\r\n",
      "    <TD class=\"details-column-right\">02-23-2021 at 12:40:18</TD></TR></TABLE>\r\n",
      "<br>\r\n",
      "\r\n",
      "<br><br>\r\n",
      "</body>\r\n",
      "</html>\r\n",
      "\r\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Send an example image to get a prediction score\n",
    "input_data_str = \"{\\\"data\\\": \" + str(input_data.tolist()) + \"}\"\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"} \n",
    "\n",
    "# Get scoring URI of local webservice\n",
    "local_scoring_uri = local_service.scoring_uri\n",
    "\n",
    "resp = requests.post(local_scoring_uri, input_data_str, headers=headers)\n",
    "\n",
    "print(\"POST to url\", local_service.scoring_uri)\n",
    "print(\"Result:\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the test image\n",
    "# %matplotlib inline\n",
    "# plt.imshow(Image.open(\"../data/fowl_data/test_img.jpg\"))\n",
    "\n",
    "# # Preprocess the image\n",
    "# input_data = preprocess_image(\"../data/fowl_data/test_img.jpg\")\n",
    "\n",
    "# # Get header and body for POST request\n",
    "# input_data = \"{\\\"data\\\": \" + str(input_data.tolist()) + \"}\"\n",
    "# headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# # Get scoring URI\n",
    "# local_scoring_uri = local_service.scoring_uri\n",
    "\n",
    "# # Make POST request\n",
    "# resp = requests.post(local_scoring_uri, input_data, headers=headers)\n",
    "\n",
    "# print(\"POST to url\", local_scoring_uri)\n",
    "# print(\"Result:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment (AKS Compute Target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section describes how a local deployment to the Azure Kubernetes Service Experimentation Instance can be done. This is a particular instance of AKS provided for model testing in the Experimentation Stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve AKS cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify AKS cluster name of the Experimentation Instance\n",
    "aks_name = \"infcluster01\" \n",
    "\n",
    "# Retrieve all computes from workspace\n",
    "cts = ws.compute_targets\n",
    "\n",
    "# Retrieve existing AKS cluster\n",
    "if aks_name in cts and cts[aks_name].type == \"AKS\":\n",
    "    print(\"Found existing AKS cluster, will use it!\\n\")\n",
    "    aks_target = cts[aks_name]\n",
    "    print(\"Cluster state:\", aks_target.provisioning_state)\n",
    "    print(\"Cluster is ready!\\n\")\n",
    "    print(aks_target)\n",
    "else:\n",
    "    print(\"Specified AKS cluster does not exist, please use the existing AKS Experimentation Instance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Model as AKS Webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify webservice name\n",
    "aks_service_name = \"fowl-pytorch-aks-service\"\n",
    "\n",
    "aks_deployment_config = AksWebservice.deploy_configuration(collect_model_data=True,\n",
    "                                                           enable_app_insights=True)\n",
    "\n",
    "aks_webservices = Webservice.list(workspace = ws, compute_type=\"AKS\")\n",
    "\n",
    "if any(aks_webservice.name == aks_service_name for aks_webservice in aks_webservices):\n",
    "    print(\"Model with the same service name is already deployed\")\n",
    "else:\n",
    "    if aks_target.provisioning_state == \"Succeeded\":\n",
    "        aks_service = Model.deploy(workspace=ws,\n",
    "                                   name=aks_service_name,\n",
    "                                   models=[model],\n",
    "                                   inference_config=inference_config,\n",
    "                                   deployment_config=aks_deployment_config,\n",
    "                                   deployment_target=aks_target)\n",
    "        \n",
    "        aks_service.wait_for_deployment(show_output=True)\n",
    "        print(\"Service state:\", aks_service.state)\n",
    "        print(\"Service details:\", aks_service)\n",
    "    else: \n",
    "        raise ValueError(\"Failed to deploy service to AKS - Error: \", aks_service.error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Existing Webservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the webservice already exists, it can also be retrieved as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify webservice name\n",
    "aks_service_name = \"fowl-pytorch-aks-service\"\n",
    "\n",
    "aks_service = AksWebservice(ws, aks_service_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webservice Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, the webservice that has been deployed to the AKS Experimentation Instance will be tested. The webservice can either be called using the Python SDK or by sending an HTTP request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the test image\n",
    "%matplotlib inline\n",
    "plt.imshow(Image.open(\"../data/fowl_data/example/example_image.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Python SDK to send input data to the service endpoint and retrieve prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "input_data = preprocess_image(\"../data/fowl_data/example/example_image.jpg\")\n",
    "\n",
    "# Run the service\n",
    "result = aks_service.run(input_data=json.dumps({\"data\": input_data.tolist()}))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get logs in case of issues\n",
    "# aks_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send HTTP Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send an HTTP request with the Python requests library. This is an example for how any REST API POST operation can retrieve prediction results from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send an example image to get a prediction score\n",
    "input_data_str = \"{\\\"data\\\": \" + str(input_data.tolist()) + \"}\"\n",
    "\n",
    "# For AKS deployment the service key needs to be in the header as well\n",
    "# AML generate two keys if key auth is enabled\n",
    "api_key1, api_key2 = aks_service.get_keys()\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\":(\"Bearer \"+ api_key1)} \n",
    "\n",
    "resp = requests.post(aks_service.scoring_uri, input_data_str, headers=headers)\n",
    "\n",
    "print(\"POST to url\", aks_service.scoring_uri)\n",
    "print(\"Result:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the web services with a simple API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Delete local webservice...\")\n",
    "local_service.delete()\n",
    "print(\"Delete AKS webservice...\")\n",
    "aks_service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
