{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE OF CONTENTS:\n",
    "---\n",
    "* [Notebook Summary](#Notebook-Summary)\n",
    "* [Setup](#Setup)\n",
    "    * [Notebook Parameters](#Notebook-Parameters)\n",
    "    * [Connect to Workspace](#Connect-to-Workspace)\n",
    "* [Compute Target](#Compute-Target)\n",
    "* [Pipeline Run Configuration & Environment](#Pipeline-Run-Configuration-&-Environment)\n",
    "* [Pipeline Inputs](#Pipeline-Inputs)\n",
    "* [Create Pipeline](#Create-Pipeline)\n",
    "    * [Training Step](#Training-Step)\n",
    "    * [Evaluate Step](#Evaluate-Step)\n",
    "    * [Register Step](#Register-Step)\n",
    "* [Publish Pipeline](#Publish-Pipeline)\n",
    "* [Run Pipeline](#Run-Pipeline)\n",
    "* [Resource Clean Up](#Resource-Clean-Up)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, an Azure Machine Learning (AML) training / retraining pipeline will be built and published. After building and publishing the pipeline, a REST endpoint can be used to trigger the pipeline from any HTTP library on any platform. This pipeline will be used in the MLOps process for continuous model retraining, e.g. when data or model drift is detected or in general when the model should be retrained. A pipeline gives a more operationalizable way of training than a script run (which was used for original model training in the `02_model_training` notebook) as it can be easily automated and run based on triggers. It also allows for chaining of different steps that can then be executed sequentially. In general, machine learning pipelines help to optimize the workflow in terms of speed, portability and reuse.\n",
    "\n",
    "The training / retraining pipeline built in this notebook will consist of three different steps that are executed sequentially:\n",
    "- Model training using the same code for training as in the `02_model_training` notebook\n",
    "- Model evaluation (comparing the newly trained model with the model currently in production or with a manual threshold)\n",
    "- Model registration (registering the newly trained model to the AML workspace based on the outcomes of the model evaluation)\n",
    "\n",
    "Check out the [AML Documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-machine-learning-pipelines) for more info on how to build pipelines in general.\n",
    "\n",
    "**Note**: The entire code of this notebook has also been refactored into the python scripts `build_train_pipeline.py` and `run_train_pipeline.py`in the `<PROJECT_ROOT/src/pipeline` folder so that the logic can be triggered inside a CI/CD workflow on Azure DevOps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.20.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import azureml\n",
    "from azureml.core import Dataset, Datastore, Environment, Experiment, Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, PublishedPipeline\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the notebook parameters which are used in the source code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the remote compute target cluster\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "# Define the name of the training environment created in the 00_environment_setup notebook\n",
    "env_name = \"dogs_clf_train_env\"\n",
    "\n",
    "# Determine whether the pipeline training run should be evaluated before model registration\n",
    "run_evaluation = True\n",
    "\n",
    "# Define the pipeline endpoint name\n",
    "pipeline_name = \"dog_clf_model_training_pipeline\"\n",
    "\n",
    "# Define the pipeline endpoint version\n",
    "# Make sure to update this every time you want to publish changes to your pipeline!!!\n",
    "pipeline_version = \"1.0\"\n",
    "\n",
    "# Define the model_name\n",
    "model_name = \"dog_clf_model\"\n",
    "\n",
    "# Define the experiment name\n",
    "experiment_name = \"stanford_dogs_classifier_train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to connect and communicate with the AML workspace, a workspace object needs to be instantiated using the AML SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the AML workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a remote compute target to run the pipeline experiments on. The below code will first check whether a compute target with name **cluster_name** (defined in the [Notebook Parameters](#Notebook-Parameters) section) already exists and if it does, will retrieve it. Otherwise it will create a new compute cluster.\n",
    "\n",
    "AML pipelines need to be run on a remote compute target and cannot be run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-06-29T13:12:27.451000+00:00', 'errors': None, 'creationTime': '2021-06-28T06:49:27.130474+00:00', 'modifiedTime': '2021-06-28T06:49:57.842385+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 2, 'nodeIdleTimeBeforeScaleDown': 'PT300S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\", # CPU\n",
    "                                                           # vm_size='STANDARD_NC6', # GPU\n",
    "                                                           max_nodes=4,\n",
    "                                                           idle_seconds_before_scaledown=2400)\n",
    "    \n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use get_status() to get a detailed status for the current cluster\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Run Configuration & Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model training environment that has been registered as part of the `00_environment_setup` notebook and use it for the pipeline run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment.get(workspace=ws, name=env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline run configuration containing the retrieved environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = RunConfiguration()\n",
    "run_config.environment = env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a PipelineData object to pass data between steps. In general, an object reference in the outputs array of one step becomes available as an input for a subsequent pipeline step for scenarios where there is more than one step.\n",
    "\n",
    "\n",
    "While here the pipeline will consist of only one step that requires access to data, a usual flow with multiple steps will include:\n",
    "- Using Dataset objects as inputs to fetch raw data, performing some transformations, then outputting a PipelineData object.\n",
    "- Use the previous step's PipelineData output object as an input object, repeated for subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data = PipelineData(\"pipeline_data\", datastore=ws.get_default_datastore())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create PipelineParameter objects to be able to pass versatile arguments to the PythonScriptSteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_param = PipelineParameter(name=\"dataset_name\", default_value=\"stanford_dogs_dataset\")\n",
    "dataset_version_param = PipelineParameter(name=\"dataset_version\", default_value=1)\n",
    "data_file_path_param = PipelineParameter(name=\"data_file_path\", default_value=\"none\")\n",
    "model_name_param = PipelineParameter(name=\"model_name\", default_value=\"dog_clf_model\")\n",
    "caller_run_id_param = PipelineParameter(name=\"caller_run_id\", default_value=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a pipeline, the individual steps need to be created first.\n",
    "\n",
    "A pipeline step is an object that encapsulates everything that is needed for running a pipeline including:\n",
    "\n",
    "- environment and dependency settings\n",
    "- the compute target to run the pipeline on\n",
    "- input and output data, and any custom parameters\n",
    "- reference to a script or SDK-logic to run during the step\n",
    "\n",
    "There are multiple classes that inherit from the parent class PipelineStep to assist with building a step using certain frameworks and stacks. Here, the PythonScriptStep class is used to define the logic of the three steps in Python scripts. These Python scripts can be found in the `<PROJECT_ROOT>/src/pipeline` folder:\n",
    "- the training step: train_model_step.py\n",
    "- the evaluate step: evaluate_model_step.py\n",
    "- the register step: register_model_step.py\n",
    "\n",
    "For a list of all classes for different step types, see the [steps package](https://docs.microsoft.com/en-gb/python/api/azureml-pipeline-steps/azureml.pipeline.steps?view=azure-ml-py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline training step using the PipelineParameter objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step has been created.\n"
     ]
    }
   ],
   "source": [
    "train_step = PythonScriptStep(name=\"Train Model\",\n",
    "                              script_name=\"pipeline/train_model_step.py\",\n",
    "                              compute_target=compute_target,\n",
    "                              source_directory=\"../src\",\n",
    "                              outputs=[pipeline_data],\n",
    "                              arguments=[\"--caller_run_id\", caller_run_id_param,\n",
    "                                         \"--dataset_name\", dataset_name_param,\n",
    "                                         \"--dataset_version\", dataset_version_param,\n",
    "                                         \"--data_file_path\", data_file_path_param,\n",
    "                                         \"--model_name\", model_name_param,\n",
    "                                         \"--step_output\", pipeline_data],\n",
    "                              runconfig=run_config,\n",
    "                              allow_reuse=False)\n",
    "\n",
    "print(\"Training step has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline evaluate step using the PipelineParameter objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate step has been created.\n"
     ]
    }
   ],
   "source": [
    "evaluate_step = PythonScriptStep(name=\"Evaluate Model\",\n",
    "                                 script_name=\"pipeline/evaluate_model_step.py\",\n",
    "                                 compute_target=compute_target,\n",
    "                                 source_directory=\"../src\",\n",
    "                                 arguments=[\"--model_name\", model_name_param,\n",
    "                                            \"--allow_run_cancel\", True],\n",
    "                                 runconfig=run_config,\n",
    "                                 allow_reuse=False)\n",
    "\n",
    "print(\"Evaluate step has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline register step using the PipelineParameter objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Register step has been created.\n"
     ]
    }
   ],
   "source": [
    "register_step = PythonScriptStep(name=\"Register Model \",\n",
    "                                 script_name=\"pipeline/register_model_step.py\",\n",
    "                                 compute_target=compute_target,\n",
    "                                 source_directory=\"../src\",\n",
    "                                 inputs=[pipeline_data],\n",
    "                                 arguments=[\"--model_name\", model_name_param,\n",
    "                                            \"--step_input\", pipeline_data],\n",
    "                                 runconfig=run_config,\n",
    "                                 allow_reuse=False)\n",
    "\n",
    "print(\"Register step has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stitch the three pipeline steps together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include evaluation step before register step.\n"
     ]
    }
   ],
   "source": [
    "# Check run_evaluation flag to include or exclude evaluation step.\n",
    "if run_evaluation == True:\n",
    "    print(\"Include evaluation step before register step.\")\n",
    "    evaluate_step.run_after(train_step)\n",
    "    register_step.run_after(evaluate_step)\n",
    "    steps = [train_step, evaluate_step, register_step]\n",
    "else:\n",
    "    print(\"Exclude evaluation step and directly run register step.\")\n",
    "    register_step.run_after(train_step)\n",
    "    steps = [train_step, register_step]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and validate the pipeline based on the pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step Train Model is ready to be created [3d73f846]\n",
      "Step Evaluate Model is ready to be created [397abf58]Step Register Model  is ready to be created [5c4eed1a]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "train_pipeline._set_experiment_name\n",
    "train_pipeline.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publish Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publish the pipeline to create a REST endpoint that allows to rerun the pipeline from any HTTP library on any platform. The published pipeline can also be run from the AML workspace where different metadata such as run history and duration are tracked as well. \n",
    "\n",
    "Before publishing the pipeline, the training parameters need to be specified in the `pipeline_parameters.json` file that can be found in the `<PROJECT_ROOT/src/config` folder:\n",
    "\n",
    "<img src=\"../docs/images/aml_pipeline_parameters.png\" alt=\"aml_pipeline_parameterss\" width=\"600\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust all parameters as desired and then run the following cell to publish the pipeline.\n",
    "\n",
    "**Note**: If a pipeline with the same version has already been published, the code will retrieve the existing published pipeline instead. This means that whenever you make changes to the pipeline you need to specify a new pipeline version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Train Model [3d73f846][7cb029e8-098f-4960-980f-e4c5d1e43a2e], (This step will run and generate new outputs)\n",
      "Created step Evaluate Model [397abf58][132248b0-cef5-449e-b122-fd53f8f87df8], (This step will run and generate new outputs)\n",
      "Created step Register Model  [5c4eed1a][bbcab9ab-1240-4388-90d3-58f5c1ad3518], (This step will run and generate new outputs)\n",
      "Published pipeline 'dog_clf_model_training_pipeline' with version 1.0.\n"
     ]
    }
   ],
   "source": [
    "pipelines = PublishedPipeline.list(ws)\n",
    "matched_pipes = []\n",
    "\n",
    "for p in pipelines:\n",
    "    if p.name == pipeline_name:\n",
    "        if p.version == pipeline_version:\n",
    "            matched_pipes.append(p)\n",
    "\n",
    "if(len(matched_pipes) == 0):\n",
    "    published_pipeline = train_pipeline.publish(name=pipeline_name,\n",
    "                                                description=\"Model training/retraining pipeline\",\n",
    "                                                version=pipeline_version)\n",
    "    \n",
    "    print(f\"Published pipeline '{published_pipeline.name}' with version {published_pipeline.version}.\")\n",
    "\n",
    "else:\n",
    "    published_pipeline = matched_pipes[0]\n",
    "    print(f\"Retrieved published pipeline with id {published_pipeline.id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is now published in the AML workspace:\n",
    "\n",
    "<img src=\"../docs/images/aml_pipeline.png\" alt=\"aml_pipeline\" width=\"1200\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first pipeline run takes more time than subsequent runs, as all dependencies must be downloaded, a Docker image is created, and the Python environment is provisioned/created. Running it again takes significantly less time as those resources are reused. Total run time depends on the workload of your scripts and processes running in each pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted PipelineRun b360d7c1-5d4d-4cf6-9147-6c69fc33c36e\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/stanford_dogs_classifier_train/runs/b360d7c1-5d4d-4cf6-9147-6c69fc33c36e?wsid=/subscriptions/e58a23da-421e-4b52-99d5-e615f2f8be41/resourcegroups/mlopstemplaterg/workspaces/mlopstemplatewsbfdc24\n"
     ]
    }
   ],
   "source": [
    "pipeline_parameters = {\"model_name\": model_name}\n",
    "tags = {\"trigger\": \"jupyter notebook\",\n",
    "        \"model_architecture\" : \"transfer-learning with ResNext-50\"}\n",
    "\n",
    "# Create an AML Experiment\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "    \n",
    "# Submit an Experiment Run using the published pipeline and defined pipeline parameters\n",
    "run = experiment.submit(published_pipeline,\n",
    "                        tags=tags,\n",
    "                        pipeline_parameters=pipeline_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: b360d7c1-5d4d-4cf6-9147-6c69fc33c36e\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/stanford_dogs_classifier_train/runs/b360d7c1-5d4d-4cf6-9147-6c69fc33c36e?wsid=/subscriptions/e58a23da-421e-4b52-99d5-e615f2f8be41/resourcegroups/mlopstemplaterg/workspaces/mlopstemplatewsbfdc24\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 14c90a42-b648-4c62-b401-838b149670cc\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/stanford_dogs_classifier_train/runs/14c90a42-b648-4c62-b401-838b149670cc?wsid=/subscriptions/e58a23da-421e-4b52-99d5-e615f2f8be41/resourcegroups/mlopstemplaterg/workspaces/mlopstemplatewsbfdc24\n",
      "StepRun( Train Model ) Status: NotStarted\n",
      "StepRun( Train Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt\n",
      "========================================================================================================================\n",
      "2021-06-29T15:06:07Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/14c90a42-b648-4c62-b401-838b149670cc/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/14c90a42-b648-4c62-b401-838b149670cc/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=316489 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/14c90a42-b648-4c62-b401-838b149670cc/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-06-29T15:06:07Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/14c90a42-b648-4c62-b401-838b149670cc/mounts/workspaceblobstore\n",
      "2021-06-29T15:06:07Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      "2021-06-29T15:06:07Z Starting output-watcher...\n",
      "2021-06-29T15:06:07Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-06-29T15:11:08Z The vmsize standard_nc6 is a GPU VM, running nvidia-smi command.\n",
      "2021-06-29T15:11:18Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-06-29T15:11:18Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_b11c6abe8ea47468eb6b58b57479f12d\n",
      "2c11b7cecaa5: Pulling fs layer\n",
      "04637fa56252: Pulling fs layer\n",
      "d6e6af23a0f3: Pulling fs layer\n",
      "b4a424de92ad: Pulling fs layer\n",
      "3e5d9ee64909: Pulling fs layer\n",
      "3a846111ff22: Pulling fs layer\n",
      "93a5020c6e19: Pulling fs layer\n",
      "360b353e68fd: Pulling fs layer\n",
      "ea4e2e1810f8: Pulling fs layer\n",
      "def12cf7de15: Pulling fs layer\n",
      "3ae6adfbdb11: Pulling fs layer\n",
      "2a21fbf2232e: Pulling fs layer\n",
      "e63c6c3852dd: Pulling fs layer\n",
      "c3293bb6674b: Pulling fs layer\n",
      "8cd7bdd3bb12: Pulling fs layer\n",
      "3c8eb715f2ef: Pulling fs layer\n",
      "b71d8774a844: Pulling fs layer\n",
      "565d7d93a611: Pulling fs layer\n",
      "9c342db2f45a: Pulling fs layer\n",
      "1042a07cb4d1: Pulling fs layer\n",
      "b024227e3ef0: Pulling fs layer\n",
      "3e5d9ee64909: Waiting\n",
      "3a846111ff22: Waiting\n",
      "93a5020c6e19: Waiting\n",
      "360b353e68fd: Waiting\n",
      "ea4e2e1810f8: Waiting\n",
      "def12cf7de15: Waiting\n",
      "3ae6adfbdb11: Waiting\n",
      "b4a424de92ad: Waiting\n",
      "2a21fbf2232e: Waiting\n",
      "e63c6c3852dd: Waiting\n",
      "9c342db2f45a: Waiting\n",
      "c3293bb6674b: Waiting\n",
      "1042a07cb4d1: Waiting\n",
      "8cd7bdd3bb12: Waiting\n",
      "b024227e3ef0: Waiting\n",
      "3c8eb715f2ef: Waiting\n",
      "b71d8774a844: Waiting\n",
      "565d7d93a611: Waiting\n",
      "d6e6af23a0f3: Verifying Checksum\n",
      "d6e6af23a0f3: Download complete\n",
      "04637fa56252: Verifying Checksum\n",
      "04637fa56252: Download complete\n",
      "b4a424de92ad: Verifying Checksum\n",
      "b4a424de92ad: Download complete\n",
      "3a846111ff22: Verifying Checksum\n",
      "3a846111ff22: Download complete\n",
      "2c11b7cecaa5: Verifying Checksum\n",
      "2c11b7cecaa5: Download complete\n",
      "93a5020c6e19: Verifying Checksum\n",
      "93a5020c6e19: Download complete\n",
      "360b353e68fd: Verifying Checksum\n",
      "360b353e68fd: Download complete\n",
      "3e5d9ee64909: Verifying Checksum\n",
      "3e5d9ee64909: Download complete\n",
      "def12cf7de15: Verifying Checksum\n",
      "def12cf7de15: Download complete\n",
      "2c11b7cecaa5: Pull complete\n",
      "04637fa56252: Pull complete\n",
      "3ae6adfbdb11: Verifying Checksum\n",
      "3ae6adfbdb11: Download complete\n",
      "2a21fbf2232e: Verifying Checksum\n",
      "2a21fbf2232e: Download complete\n",
      "d6e6af23a0f3: Pull complete\n",
      "b4a424de92ad: Pull complete\n",
      "e63c6c3852dd: Verifying Checksum\n",
      "e63c6c3852dd: Download complete\n",
      "3c8eb715f2ef: Verifying Checksum\n",
      "3c8eb715f2ef: Download complete\n",
      "8cd7bdd3bb12: Download complete\n",
      "565d7d93a611: Verifying Checksum\n",
      "565d7d93a611: Download complete\n",
      "9c342db2f45a: Verifying Checksum\n",
      "9c342db2f45a: Download complete\n",
      "1042a07cb4d1: Download complete\n",
      "b024227e3ef0: Verifying Checksum\n",
      "b024227e3ef0: Download complete\n",
      "ea4e2e1810f8: Verifying Checksum\n",
      "ea4e2e1810f8: Download complete\n",
      "3e5d9ee64909: Pull complete\n",
      "3a846111ff22: Pull complete\n",
      "93a5020c6e19: Pull complete\n",
      "360b353e68fd: Pull complete\n",
      "ea4e2e1810f8: Pull complete\n",
      "def12cf7de15: Pull complete\n",
      "3ae6adfbdb11: Pull complete\n",
      "2a21fbf2232e: Pull complete\n",
      "e63c6c3852dd: Pull complete\n",
      "c3293bb6674b: Pull complete\n",
      "8cd7bdd3bb12: Pull complete\n",
      "3c8eb715f2ef: Pull complete\n",
      "b71d8774a844: Download complete\n",
      "b71d8774a844: Pull complete\n",
      "565d7d93a611: Pull complete\n",
      "9c342db2f45a: Pull complete\n",
      "1042a07cb4d1: Pull complete\n",
      "b024227e3ef0: Pull complete\n",
      "Digest: sha256:86e63ab6e93bc969f5fa5be0975590b92d33458c86c2d1237ef7b8406dd06374\n",
      "Status: Downloaded newer image for 4d3602983f8547aa8deaeb9718806017.azurecr.io/azureml/azureml_b11c6abe8ea47468eb6b58b57479f12d:latest\n",
      "4d3602983f8547aa8deaeb9718806017.azurecr.io/azureml/azureml_b11c6abe8ea47468eb6b58b57479f12d:latest\n",
      "2021-06-29T15:12:13Z Check if container 14c90a42-b648-4c62-b401-838b149670cc already exist exited with 0, \n",
      "\n",
      "7dd6198266a9ed621d13af3469f36b845bdc5df404c3cf42197d93e289d55479\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/06/29 15:12:33 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/06/29 15:12:33 Version: 3.0.01632.0003 Branch: .SourceBranch Commit: 4b96fb0\n",
      "2021/06/29 15:12:33 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/06/29 15:12:33 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "[2021-06-29T15:12:33.527401] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['pipeline/train_model_step.py', '--caller_run_id', 'none', '--dataset_name', 'stanford_dogs_dataset', '--dataset_version', '1', '--data_file_path', 'none', '--model_name', 'dog_clf_model', '--step_output', '/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/14c90a42-b648-4c62-b401-838b149670cc/mounts/workspaceblobstore/azureml/14c90a42-b648-4c62-b401-838b149670cc/pipeline_data'])\n",
      "Script type = None\n",
      "[2021-06-29T15:12:34.219195] Entering Run History Context Manager.\n",
      "[2021-06-29T15:12:35.349358] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/14c90a42-b648-4c62-b401-838b149670cc/wd/azureml/14c90a42-b648-4c62-b401-838b149670cc\n",
      "[2021-06-29T15:12:35.349584] Preparing to call script [pipeline/train_model_step.py] with arguments:['--caller_run_id', 'none', '--dataset_name', 'stanford_dogs_dataset', '--dataset_version', '1', '--data_file_path', 'none', '--model_name', 'dog_clf_model', '--step_output', '/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/14c90a42-b648-4c62-b401-838b149670cc/mounts/workspaceblobstore/azureml/14c90a42-b648-4c62-b401-838b149670cc/pipeline_data']\n",
      "[2021-06-29T15:12:35.349675] After variable expansion, calling script [pipeline/train_model_step.py] with arguments:['--caller_run_id', 'none', '--dataset_name', 'stanford_dogs_dataset', '--dataset_version', '1', '--data_file_path', 'none', '--model_name', 'dog_clf_model', '--step_output', '/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/14c90a42-b648-4c62-b401-838b149670cc/mounts/workspaceblobstore/azureml/14c90a42-b648-4c62-b401-838b149670cc/pipeline_data']\n",
      "\n",
      "Running train_model_step.py\n",
      "Argument [caller_run_id]: none\n",
      "Argument [dataset_name]: stanford_dogs_dataset\n",
      "Argument [dataset_version]: 1\n",
      "Argument [data_file_path]: none\n",
      "Argument [model_name]: dog_clf_model\n",
      "Argument [step_output]: /mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/14c90a42-b648-4c62-b401-838b149670cc/mounts/workspaceblobstore/azureml/14c90a42-b648-4c62-b401-838b149670cc/pipeline_data\n",
      "\n",
      "Getting training parameters\n",
      "Parameters: {'num_epochs': 36, 'batch_size': 8, 'learning_rate': 0.01, 'momentum': 0.9, 'num_frozen_layers': 7, 'num_neurons_fc_layer': 512, 'dropout_prob_fc_layer': 0.0, 'lr_scheduler_step_size': 7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021/06/29 15:12:38 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "--------------------\n",
      "START MODEL TRAINING\n",
      "--------------------\n",
      "Hyperparameter number of epochs: 36\n",
      "Hyperparameter batch size: 8\n",
      "Hyperparameter learning rate: 0.01\n",
      "Hyperparameter momentum: 0.9\n",
      "Hyperparameter number of frozen layers: 7\n",
      "Hyperparameter number of neurons fc layer: 512\n",
      "Hyperparameter dropout probability fc layer: 0\n",
      "Hyperparameter lr scheduler step size: 7\n",
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n",
      "\n",
      "  0%|          | 0.00/95.8M [00:00<?, ?B/s]\n",
      "  9%|▉         | 8.77M/95.8M [00:00<00:00, 91.9MB/s]\n",
      " 33%|███▎      | 31.5M/95.8M [00:00<00:00, 113MB/s] \n",
      " 53%|█████▎    | 50.6M/95.8M [00:00<00:00, 130MB/s]\n",
      " 74%|███████▍  | 71.1M/95.8M [00:00<00:00, 147MB/s]\n",
      " 94%|█████████▍| 90.0M/95.8M [00:00<00:00, 160MB/s]\n",
      "100%|██████████| 95.8M/95.8M [00:00<00:00, 191MB/s]\n",
      "--------------------\n",
      "Epoch 1/36\n",
      "--------------------\n",
      "Train Loss: 2.3663 Train Acc: 0.4342\n",
      "Val Loss: 0.9627 Val Acc: 0.7421\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 2/36\n",
      "--------------------\n",
      "Train Loss: 1.8241 Train Acc: 0.5310\n",
      "Val Loss: 0.8500 Val Acc: 0.7754\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 3/36\n",
      "--------------------\n",
      "Train Loss: 1.7857 Train Acc: 0.5621\n",
      "Val Loss: 0.9523 Val Acc: 0.7629\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 4/36\n",
      "--------------------\n",
      "Train Loss: 1.7794 Train Acc: 0.5697\n",
      "Val Loss: 0.7212 Val Acc: 0.8179\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 5/36\n",
      "--------------------\n",
      "Train Loss: 1.7522 Train Acc: 0.5891\n",
      "Val Loss: 0.8560 Val Acc: 0.7992\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 6/36\n",
      "--------------------\n",
      "Train Loss: 1.7192 Train Acc: 0.5972\n",
      "Val Loss: 0.9065 Val Acc: 0.7917\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 7/36\n",
      "--------------------\n",
      "Train Loss: 1.7515 Train Acc: 0.6105\n",
      "Val Loss: 0.7912 Val Acc: 0.8071\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 8/36\n",
      "--------------------\n",
      "Train Loss: 1.0333 Train Acc: 0.7132\n",
      "Val Loss: 0.4655 Val Acc: 0.8617\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 9/36\n",
      "--------------------\n",
      "Train Loss: 0.9042 Train Acc: 0.7353\n",
      "Val Loss: 0.3913 Val Acc: 0.8821\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 10/36\n",
      "--------------------\n",
      "Train Loss: 0.8533 Train Acc: 0.7508\n",
      "Val Loss: 0.4104 Val Acc: 0.8863\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 11/36\n",
      "--------------------\n",
      "Train Loss: 0.8679 Train Acc: 0.7539\n",
      "Val Loss: 0.4035 Val Acc: 0.8767\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 12/36\n",
      "--------------------\n",
      "Train Loss: 0.8461 Train Acc: 0.7569\n",
      "Val Loss: 0.4287 Val Acc: 0.8725\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 13/36\n",
      "--------------------\n",
      "Train Loss: 0.8247 Train Acc: 0.7569\n",
      "Val Loss: 0.4396 Val Acc: 0.8758\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 14/36\n",
      "--------------------\n",
      "Train Loss: 0.8203 Train Acc: 0.7613\n",
      "Val Loss: 0.4161 Val Acc: 0.8779\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 15/36\n",
      "--------------------\n",
      "Train Loss: 0.7789 Train Acc: 0.7721\n",
      "Val Loss: 0.4084 Val Acc: 0.8788\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 16/36\n",
      "--------------------\n",
      "Train Loss: 0.7515 Train Acc: 0.7786\n",
      "Val Loss: 0.3730 Val Acc: 0.8879\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 17/36\n",
      "--------------------\n",
      "Train Loss: 0.7541 Train Acc: 0.7793\n",
      "Val Loss: 0.3993 Val Acc: 0.8879\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 18/36\n",
      "--------------------\n",
      "Train Loss: 0.7595 Train Acc: 0.7824\n",
      "Val Loss: 0.3909 Val Acc: 0.8829\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 19/36\n",
      "--------------------\n",
      "Train Loss: 0.7608 Train Acc: 0.7779\n",
      "Val Loss: 0.3999 Val Acc: 0.8821\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 20/36\n",
      "--------------------\n",
      "Train Loss: 0.7141 Train Acc: 0.7905\n",
      "Val Loss: 0.4259 Val Acc: 0.8775\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 21/36\n",
      "--------------------\n",
      "Train Loss: 0.7290 Train Acc: 0.7881\n",
      "Val Loss: 0.3972 Val Acc: 0.8825\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 22/36\n",
      "--------------------\n",
      "Train Loss: 0.7476 Train Acc: 0.7828\n",
      "Val Loss: 0.3885 Val Acc: 0.8883\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 23/36\n",
      "--------------------\n",
      "Train Loss: 0.7377 Train Acc: 0.7797\n",
      "Val Loss: 0.3662 Val Acc: 0.8883\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 24/36\n",
      "--------------------\n",
      "Train Loss: 0.7181 Train Acc: 0.7914\n",
      "Val Loss: 0.3561 Val Acc: 0.8883\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 25/36\n",
      "--------------------\n",
      "Train Loss: 0.7028 Train Acc: 0.7956\n",
      "Val Loss: 0.3790 Val Acc: 0.8858\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 26/36\n",
      "--------------------\n",
      "Train Loss: 0.7306 Train Acc: 0.7861\n",
      "Val Loss: 0.3732 Val Acc: 0.8858\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 27/36\n",
      "--------------------\n",
      "Train Loss: 0.7255 Train Acc: 0.7898\n",
      "Val Loss: 0.3689 Val Acc: 0.8900\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 28/36\n",
      "--------------------\n",
      "Train Loss: 0.7421 Train Acc: 0.7836\n",
      "Val Loss: 0.3864 Val Acc: 0.8892\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 29/36\n",
      "--------------------\n",
      "Train Loss: 0.7264 Train Acc: 0.7864\n",
      "Val Loss: 0.4118 Val Acc: 0.8754\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 30/36\n",
      "--------------------\n",
      "Train Loss: 0.7178 Train Acc: 0.7875\n",
      "Val Loss: 0.4166 Val Acc: 0.8783\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 31/36\n",
      "--------------------\n",
      "Train Loss: 0.7467 Train Acc: 0.7773\n",
      "Val Loss: 0.4059 Val Acc: 0.8758\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 32/36\n",
      "--------------------\n",
      "Train Loss: 0.7237 Train Acc: 0.7872\n",
      "Val Loss: 0.3990 Val Acc: 0.8821\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 33/36\n",
      "--------------------\n",
      "Train Loss: 0.7077 Train Acc: 0.7916\n",
      "Val Loss: 0.3754 Val Acc: 0.8829\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 34/36\n",
      "--------------------\n",
      "Train Loss: 0.7216 Train Acc: 0.7890\n",
      "Val Loss: 0.3855 Val Acc: 0.8888\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 35/36\n",
      "--------------------\n",
      "Train Loss: 0.7379 Train Acc: 0.7824\n",
      "Val Loss: 0.3834 Val Acc: 0.8888\n",
      "--------------------\n",
      "--------------------\n",
      "Epoch 36/36\n",
      "--------------------\n",
      "Train Loss: 0.7367 Train Acc: 0.7864\n",
      "Val Loss: 0.3700 Val Acc: 0.8863\n",
      "--------------------\n",
      "Training completed in 103m 44s\n",
      "Best validation accuracy: 0.890000\n",
      "Logging model metrics\n",
      "Metrics {'test_acc': 0.8918414918414919}\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt\n",
      "===============================================================================================================\n",
      "[2021-06-29T16:59:35.137543] Entering job release\n",
      "[2021-06-29T16:59:36.461918] Starting job release\n",
      "[2021-06-29T16:59:36.463103] Logging experiment finalizing status in history service.[2021-06-29T16:59:36.463480] job release stage : upload_datastore starting...\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 14827\n",
      "\n",
      "[2021-06-29T16:59:36.463863] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-06-29T16:59:36.466054] job release stage : copy_batchai_cached_logs starting...[2021-06-29T16:59:36.466096] job release stage : execute_job_release starting...\n",
      "\n",
      "[2021-06-29T16:59:36.466496] Entering context manager injector.[2021-06-29T16:59:36.474458] job release stage : copy_batchai_cached_logs completed...\n",
      "\n",
      "[2021-06-29T16:59:36.534399] job release stage : upload_datastore completed...\n",
      "[2021-06-29T16:59:36.628243] job release stage : send_run_telemetry starting...\n",
      "[2021-06-29T16:59:36.653063] get vm size and vm region successfully.\n",
      "[2021-06-29T16:59:36.662222] get compute meta data successfully.\n",
      "[2021-06-29T16:59:36.709444] job release stage : execute_job_release completed...\n",
      "[2021-06-29T16:59:37.008361] post artifact meta request successfully.\n",
      "[2021-06-29T16:59:37.048356] upload compute record artifact successfully.\n",
      "[2021-06-29T16:59:37.048418] job release stage : send_run_telemetry completed...\n",
      "[2021-06-29T16:59:37.048713] Job release is complete\n",
      "\n",
      "StepRun(Train Model) Execution Summary\n",
      "=======================================\n",
      "StepRun( Train Model ) Status: Finished\n",
      "{'runId': '14c90a42-b648-4c62-b401-838b149670cc', 'target': 'gpu-cluster', 'status': 'Completed', 'startTimeUtc': '2021-06-29T15:06:11.288499Z', 'endTimeUtc': '2021-06-29T17:00:08.844625Z', 'properties': {'azureml.git.repository_uri': 'https://github.com/sebastianbirk/pytorch-mlops-template-azure-ml.git', 'mlflow.source.git.repoURL': 'https://github.com/sebastianbirk/pytorch-mlops-template-azure-ml.git', 'azureml.git.branch': 'develop', 'mlflow.source.git.branch': 'develop', 'azureml.git.commit': '24ee5abcfc13dfd6c7da3ede3b9f3013132587b1', 'mlflow.source.git.commit': '24ee5abcfc13dfd6c7da3ede3b9f3013132587b1', 'azureml.git.dirty': 'True', 'ContentSnapshotId': 'a77d3106-296d-4662-949a-a22a25b989ae', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '7cb029e8-098f-4960-980f-e4c5d1e43a2e', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '3d73f846', 'azureml.pipelinerunid': 'b360d7c1-5d4d-4cf6-9147-6c69fc33c36e', 'azureml.pipelineid': 'b6216aa0-5fee-44d8-b064-98cd8f278ab6', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'dbcee43d-69a3-4f3e-b579-776251e0133e'}, 'consumptionDetails': {'type': 'Reference'}}], 'outputDatasets': [], 'runDefinition': {'script': 'pipeline/train_model_step.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--caller_run_id', '$AML_PARAMETER_caller_run_id', '--dataset_name', '$AML_PARAMETER_dataset_name', '--dataset_version', '$AML_PARAMETER_dataset_version', '--data_file_path', '$AML_PARAMETER_data_file_path', '--model_name', '$AML_PARAMETER_model_name', '--step_output', '$AZUREML_DATAREFERENCE_pipeline_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpu-cluster', 'dataReferences': {'pipeline_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/14c90a42-b648-4c62-b401-838b149670cc/pipeline_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'dogs_clf_train_env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge', 'pytorch'], 'dependencies': ['joblib=0.13.2', 'matplotlib=3.3.3', 'pip=21.0.1', 'python=3.7.1', 'python-dotenv=0.8.2', 'pytorch::pytorch=1.7.0', 'pytorch::torchvision=0.8.1', 'scipy=1.6.0', 'tqdm=4.38.0', {'pip': ['azure-cli==2.3.1', 'azureml-core==1.20.0', 'azureml-defaults', 'azureml-sdk', 'azureml-widgets']}], 'name': 'azureml_7e4004f9dc5d19006a729afa49674785'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20201113.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': None, 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_caller_run_id': 'none', 'AML_PARAMETER_dataset_name': 'stanford_dogs_dataset', 'AML_PARAMETER_dataset_version': '1', 'AML_PARAMETER_data_file_path': 'none', 'AML_PARAMETER_model_name': 'dog_clf_model'}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/azureml-logs/55_azureml-execution-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt?sv=2019-02-02&sr=b&sig=Yih6NGEjwxVPh6er8RkeUd09oaRRQDDE%2Bd%2BgqVGTXd8%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'azureml-logs/65_job_prep-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/azureml-logs/65_job_prep-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt?sv=2019-02-02&sr=b&sig=Tt%2Fi%2BNnuJpP%2BrR3vJOAsoRreLZ10Dqmd6XVUXB0TR9Q%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=kkdlp4baGtOyRD6xyNLngsF2187gxYyI9Iowjx6HbVM%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'azureml-logs/75_job_post-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/azureml-logs/75_job_post-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt?sv=2019-02-02&sr=b&sig=CHxFjsYfT5RtRoW7doA1IGGgPDBE86TZEfc6Zx7nqEE%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'azureml-logs/process_info.json': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=%2FjTx0Z0E99ZAEOPjJ0bbhx%2BxlEtjPkzsxHInq5JBQzw%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'azureml-logs/process_status.json': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=bKlimDpWatOhpck7odF4sCuEs0Ta3FcKDCBGQ5lJcxg%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/120_azureml.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/120_azureml.log?sv=2019-02-02&sr=b&sig=MpRL6qS%2BzIOlU7WmvJ2dyXv2a0B4WQpftuRBCG1wdHg%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=jV6I8vQbaLxwSygGT%2FnnNF%2FiC9gsL%2F5HTjSObstyHJs%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.0.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/dataprep/backgroundProcess_Telemetry.0.log?sv=2019-02-02&sr=b&sig=5ouEKcqLfiOuMTn%2FDGQ40GE6uAkvDF8kGmjil6kThi4%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=GwhKNanzqzzcWDCnQnX3Utk%2B1z2Pj2Sg7qlUhx4y44o%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/dataprep/engine_spans_919c28b3-5963-4347-908e-c45209f4aa58.jsonl': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/dataprep/engine_spans_919c28b3-5963-4347-908e-c45209f4aa58.jsonl?sv=2019-02-02&sr=b&sig=J%2FhgDKP5oGj%2FWcKBHnTX6hehyKrEbe4LSjlnMMsph58%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/dataprep/python_span_068b4f15-8d7f-4396-816b-9c94c37eae50.jsonl': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/dataprep/python_span_068b4f15-8d7f-4396-816b-9c94c37eae50.jsonl?sv=2019-02-02&sr=b&sig=g%2FdUlkqA9uGsGbabhIApIjU%2B%2FJv1KuEZssDvC0wC9GQ%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/dataprep/python_span_0d9da3fb-1ca0-4aaf-a6c4-b9875deef72d.jsonl': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/dataprep/python_span_0d9da3fb-1ca0-4aaf-a6c4-b9875deef72d.jsonl?sv=2019-02-02&sr=b&sig=4YV5TjBa0VO%2F7smCOjGC4BorD48evtKnimb5J8Wo6Xs%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/dataprep/python_span_919c28b3-5963-4347-908e-c45209f4aa58.jsonl': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/dataprep/python_span_919c28b3-5963-4347-908e-c45209f4aa58.jsonl?sv=2019-02-02&sr=b&sig=nkHFqRX556pgGtNVamJFavbEwOfnmqDGFTp%2FNKNryRI%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=nARDgr%2BNYQF3QWk8vH2d8jpG%2BkEqVA2%2FexuCmrRfGhw%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=YFHjPfifBnjRRshrE5Z5obB3dTfCKQQ%2BANXfs2UdA%2F4%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=TZ2KxM4BGH7OnsIDNuz4RYyyIogPYAzfIlnv4p97opc%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=uzTKzb1yLjqm5VNqnDN9ZHOXtpQefU3B%2BfyyF5xQQKM%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.14c90a42-b648-4c62-b401-838b149670cc/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=DCV78zN4Iu4pfkwMxLEwnt6l50TaCT%2B5Z9TA%2Fwb44pY%3D&st=2021-06-29T16%3A49%3A39Z&se=2021-06-30T00%3A59%3A39Z&sp=r'}, 'submittedBy': 'Sebastian Birk'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 8a81375d-6e42-4c6a-b508-d1e04a03e758\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/stanford_dogs_classifier_train/runs/8a81375d-6e42-4c6a-b508-d1e04a03e758?wsid=/subscriptions/e58a23da-421e-4b52-99d5-e615f2f8be41/resourcegroups/mlopstemplaterg/workspaces/mlopstemplatewsbfdc24\n",
      "StepRun( Evaluate Model ) Status: NotStarted\n",
      "StepRun( Evaluate Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt\n",
      "========================================================================================================================\n",
      "2021-06-29T17:00:28Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/8a81375d-6e42-4c6a-b508-d1e04a03e758/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/8a81375d-6e42-4c6a-b508-d1e04a03e758/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=310703 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/8a81375d-6e42-4c6a-b508-d1e04a03e758/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-06-29T17:00:28Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/8a81375d-6e42-4c6a-b508-d1e04a03e758/mounts/workspaceblobstore\n",
      "2021-06-29T17:00:29Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      "2021-06-29T17:00:29Z Starting output-watcher...\n",
      "2021-06-29T17:00:29Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-06-29T17:05:29Z The vmsize standard_nc6 is a GPU VM, running nvidia-smi command.\n",
      "2021-06-29T17:05:39Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-06-29T17:05:39Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_b11c6abe8ea47468eb6b58b57479f12d\n",
      "Digest: sha256:86e63ab6e93bc969f5fa5be0975590b92d33458c86c2d1237ef7b8406dd06374\n",
      "Status: Image is up to date for 4d3602983f8547aa8deaeb9718806017.azurecr.io/azureml/azureml_b11c6abe8ea47468eb6b58b57479f12d:latest\n",
      "4d3602983f8547aa8deaeb9718806017.azurecr.io/azureml/azureml_b11c6abe8ea47468eb6b58b57479f12d:latest\n",
      "2021-06-29T17:05:39Z Check if container 8a81375d-6e42-4c6a-b508-d1e04a03e758 already exist exited with 0, \n",
      "\n",
      "40f658368d04942f2558259d5d93ade3ddc50df232044ef2ae12fde5abb254f2\n",
      "2021-06-29T17:05:39Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-06-29T17:05:39Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-efb45eea867acdd92a6abeeaf3706c98-442f6134af6a418d-01 -sshRequired=false] \n",
      "2021/06/29 17:05:39 Starting App Insight Logger for task:  containerSetup\n",
      "2021/06/29 17:05:39 Version: 3.0.01632.0003 Branch: .SourceBranch Commit: 4b96fb0\n",
      "2021/06/29 17:05:39 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/06/29 17:05:39 Starting infiniband setup\n",
      "2021/06/29 17:05:39 Python Version found is Python 3.7.1\n",
      "\n",
      "2021/06/29 17:05:39 Returning Python Version as 3.7\n",
      "2021-06-29T17:05:39Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/06/29 17:05:39 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/06/29 17:05:39 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/06/29 17:05:39 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-06-29T17:05:39Z Not setting up Infiniband in Container\n",
      "2021/06/29 17:05:39 Not setting up Infiniband in Container\n",
      "2021/06/29 17:05:39 Not setting up Infiniband in Container\n",
      "2021/06/29 17:05:39 Python Version found is Python 3.7.1\n",
      "\n",
      "2021/06/29 17:05:39 Returning Python Version as 3.7\n",
      "2021/06/29 17:05:39 sshd inside container not required for job, skipping setup.\n",
      "2021/06/29 17:05:40 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/06/29 17:05:40 App Insight Client has already been closed\n",
      "2021/06/29 17:05:40 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-06-29T17:05:40Z Starting docker container succeeded.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt\n",
      "===============================================================================================================\n",
      "[2021-06-29T17:05:58.547005] Entering job release\n",
      "[2021-06-29T17:05:59.894378] Starting job release\n",
      "[2021-06-29T17:05:59.895155] Logging experiment finalizing status in history service.[2021-06-29T17:05:59.895512] job release stage : upload_datastore starting...\n",
      "[2021-06-29T17:05:59.895740] job release stage : start importing azureml.history._tracking in run_history_release.Starting the daemon thread to refresh tokens in background for process with pid = 197\n",
      "\n",
      "[2021-06-29T17:05:59.896101] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-06-29T17:05:59.896248] job release stage : execute_job_release starting...\n",
      "\n",
      "[2021-06-29T17:05:59.897073] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-06-29T17:05:59.907233] Entering context manager injector.\n",
      "[2021-06-29T17:05:59.916226] job release stage : upload_datastore completed...\n",
      "[2021-06-29T17:06:00.009427] job release stage : send_run_telemetry starting...\n",
      "[2021-06-29T17:06:00.068183] get vm size and vm region successfully.\n",
      "[2021-06-29T17:06:00.077008] get compute meta data successfully.\n",
      "[2021-06-29T17:06:00.136820] job release stage : execute_job_release completed...\n",
      "[2021-06-29T17:06:00.296363] post artifact meta request successfully.\n",
      "[2021-06-29T17:06:00.326134] upload compute record artifact successfully.\n",
      "[2021-06-29T17:06:00.326188] job release stage : send_run_telemetry completed...\n",
      "[2021-06-29T17:06:00.326420] Job release is complete\n",
      "\n",
      "StepRun(Evaluate Model) Execution Summary\n",
      "==========================================\n",
      "StepRun( Evaluate Model ) Status: Finished\n",
      "{'runId': '8a81375d-6e42-4c6a-b508-d1e04a03e758', 'target': 'gpu-cluster', 'status': 'Completed', 'startTimeUtc': '2021-06-29T17:00:31.095109Z', 'endTimeUtc': '2021-06-29T17:06:15.644371Z', 'properties': {'azureml.git.repository_uri': 'https://github.com/sebastianbirk/pytorch-mlops-template-azure-ml.git', 'mlflow.source.git.repoURL': 'https://github.com/sebastianbirk/pytorch-mlops-template-azure-ml.git', 'azureml.git.branch': 'develop', 'mlflow.source.git.branch': 'develop', 'azureml.git.commit': '24ee5abcfc13dfd6c7da3ede3b9f3013132587b1', 'mlflow.source.git.commit': '24ee5abcfc13dfd6c7da3ede3b9f3013132587b1', 'azureml.git.dirty': 'True', 'ContentSnapshotId': 'a77d3106-296d-4662-949a-a22a25b989ae', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '132248b0-cef5-449e-b122-fd53f8f87df8', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '397abf58', 'azureml.pipelinerunid': 'b360d7c1-5d4d-4cf6-9147-6c69fc33c36e', 'azureml.pipelineid': 'b6216aa0-5fee-44d8-b064-98cd8f278ab6', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'pipeline/evaluate_model_step.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_name', '$AML_PARAMETER_model_name', '--allow_run_cancel', 'True'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpu-cluster', 'dataReferences': {}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'dogs_clf_train_env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge', 'pytorch'], 'dependencies': ['joblib=0.13.2', 'matplotlib=3.3.3', 'pip=21.0.1', 'python=3.7.1', 'python-dotenv=0.8.2', 'pytorch::pytorch=1.7.0', 'pytorch::torchvision=0.8.1', 'scipy=1.6.0', 'tqdm=4.38.0', {'pip': ['azure-cli==2.3.1', 'azureml-core==1.20.0', 'azureml-defaults', 'azureml-sdk', 'azureml-widgets']}], 'name': 'azureml_7e4004f9dc5d19006a729afa49674785'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20201113.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': None, 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_model_name': 'dog_clf_model'}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/azureml-logs/55_azureml-execution-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt?sv=2019-02-02&sr=b&sig=17Wx%2Ba2d0rzNuE2K1TIHzcH2kqLH9FwtTdGOaHtVyw8%3D&st=2021-06-29T16%3A56%3A00Z&se=2021-06-30T01%3A06%3A00Z&sp=r', 'azureml-logs/65_job_prep-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/azureml-logs/65_job_prep-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt?sv=2019-02-02&sr=b&sig=WMsqjThYz7Kffu8dP9RtG9cYAYYgW%2B46kCp2gs1k%2Fyk%3D&st=2021-06-29T16%3A56%3A00Z&se=2021-06-30T01%3A06%3A00Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=cepqplTELF7SaWQD8Ebz8BdC9LMEPOgBbLJ6ZcXBz%2Bc%3D&st=2021-06-29T16%3A56%3A00Z&se=2021-06-30T01%3A06%3A00Z&sp=r', 'azureml-logs/75_job_post-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/azureml-logs/75_job_post-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt?sv=2019-02-02&sr=b&sig=MDkQbsKjna5eKdWW70GLvCoyuiqkAO7tq1j%2FSCDYn%2F0%3D&st=2021-06-29T16%3A56%3A00Z&se=2021-06-30T01%3A06%3A00Z&sp=r', 'azureml-logs/process_info.json': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=qrJJhb0fYV7u8rjBrYswkC6PLZaoPk0FWZs6NHyclbk%3D&st=2021-06-29T16%3A56%3A00Z&se=2021-06-30T01%3A06%3A00Z&sp=r', 'azureml-logs/process_status.json': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=fWnAUwkedfvP0XHHFg%2BFzat%2BJaLi%2FtuBDTT3SOACu5E%3D&st=2021-06-29T16%3A56%3A00Z&se=2021-06-30T01%3A06%3A00Z&sp=r', 'logs/azureml/107_azureml.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/logs/azureml/107_azureml.log?sv=2019-02-02&sr=b&sig=VcMGwMvBMIpvqffhJSlA2T8xlV3T4erDTrnyExcoi%2FY%3D&st=2021-06-29T16%3A56%3A05Z&se=2021-06-30T01%3A06%3A05Z&sp=r', 'logs/azureml/dataprep/python_span_8a4aff51-0dd4-4a66-93c0-abb977fe0fa4.jsonl': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/logs/azureml/dataprep/python_span_8a4aff51-0dd4-4a66-93c0-abb977fe0fa4.jsonl?sv=2019-02-02&sr=b&sig=7Y5cLTy%2FyRB4ZZ2xZvGGna5%2FnjaWtDqy5UCyGKU%2FjLg%3D&st=2021-06-29T16%3A56%3A05Z&se=2021-06-30T01%3A06%3A05Z&sp=r', 'logs/azureml/dataprep/python_span_95c69350-9d1f-4ea6-a2e3-dc2c5cb8b3e4.jsonl': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/logs/azureml/dataprep/python_span_95c69350-9d1f-4ea6-a2e3-dc2c5cb8b3e4.jsonl?sv=2019-02-02&sr=b&sig=cxwrYvS9EwJKvbMh1WVlkxWccYDpN9YK7LEb1PT75Ko%3D&st=2021-06-29T16%3A56%3A05Z&se=2021-06-30T01%3A06%3A05Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=%2FVRSlmGYhRKHKGaBOIiI2S3lxB4dlr5OGUwYMzUFImY%3D&st=2021-06-29T16%3A56%3A05Z&se=2021-06-30T01%3A06%3A05Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=qQOg4IWtKAPOOCQ6qPRTUxWHyAThPSgC%2F44J8MwAuak%3D&st=2021-06-29T16%3A56%3A05Z&se=2021-06-30T01%3A06%3A05Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=95qgwjhyrDieUD%2BwEdZ21ZSGGXW8YLmSKSwu%2BHwrsTY%3D&st=2021-06-29T16%3A56%3A05Z&se=2021-06-30T01%3A06%3A05Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=EstoeNZLWOpsr7l54RcJ%2B3Jx18nunDQ6msszbTCjq5I%3D&st=2021-06-29T16%3A56%3A05Z&se=2021-06-30T01%3A06%3A05Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.8a81375d-6e42-4c6a-b508-d1e04a03e758/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=GIMMNNgwVgTDR7h9ZSDau745jsknd%2FJYoxRoeT7oIHc%3D&st=2021-06-29T16%3A56%3A05Z&se=2021-06-30T01%3A06%3A05Z&sp=r'}, 'submittedBy': 'Sebastian Birk'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: b0462b01-c067-44d6-b2e2-1963cfde2b66\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/stanford_dogs_classifier_train/runs/b0462b01-c067-44d6-b2e2-1963cfde2b66?wsid=/subscriptions/e58a23da-421e-4b52-99d5-e615f2f8be41/resourcegroups/mlopstemplaterg/workspaces/mlopstemplatewsbfdc24\n",
      "StepRun( Register Model  ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt\n",
      "========================================================================================================================\n",
      "2021-06-29T17:06:30Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/b0462b01-c067-44d6-b2e2-1963cfde2b66/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/b0462b01-c067-44d6-b2e2-1963cfde2b66/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=310703 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/b0462b01-c067-44d6-b2e2-1963cfde2b66/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-06-29T17:06:30Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/b0462b01-c067-44d6-b2e2-1963cfde2b66/mounts/workspaceblobstore\n",
      "2021-06-29T17:06:30Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      "2021-06-29T17:06:30Z Starting output-watcher...\n",
      "2021-06-29T17:06:30Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-06-29T17:11:31Z The vmsize standard_nc6 is a GPU VM, running nvidia-smi command.\n",
      "2021-06-29T17:11:39Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-06-29T17:11:39Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_b11c6abe8ea47468eb6b58b57479f12d\n",
      "Digest: sha256:86e63ab6e93bc969f5fa5be0975590b92d33458c86c2d1237ef7b8406dd06374\n",
      "Status: Image is up to date for 4d3602983f8547aa8deaeb9718806017.azurecr.io/azureml/azureml_b11c6abe8ea47468eb6b58b57479f12d:latest\n",
      "4d3602983f8547aa8deaeb9718806017.azurecr.io/azureml/azureml_b11c6abe8ea47468eb6b58b57479f12d:latest\n",
      "2021-06-29T17:11:39Z Check if container b0462b01-c067-44d6-b2e2-1963cfde2b66 already exist exited with 0, \n",
      "\n",
      "99d6f0ec4cb18bbb59d8c17aaa820038962c01b7241a8da3ea606ea94d40f891\n",
      "2021-06-29T17:11:39Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-06-29T17:11:39Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-2e976b6f34f35a226bf51a17f6fab283-d3c275720d2cc7bf-01 -sshRequired=false] \n",
      "2021/06/29 17:11:39 Starting App Insight Logger for task:  containerSetup\n",
      "2021/06/29 17:11:39 Version: 3.0.01632.0003 Branch: .SourceBranch Commit: 4b96fb0\n",
      "2021/06/29 17:11:39 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/06/29 17:11:39 Starting infiniband setup\n",
      "2021/06/29 17:11:39 Python Version found is Python 3.7.1\n",
      "\n",
      "2021/06/29 17:11:39 Returning Python Version as 3.7\n",
      "2021-06-29T17:11:39Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/06/29 17:11:39 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/06/29 17:11:39 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/06/29 17:11:39 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-06-29T17:11:39Z Not setting up Infiniband in Container\n",
      "2021/06/29 17:11:39 Not setting up Infiniband in Container\n",
      "2021/06/29 17:11:39 Not setting up Infiniband in Container\n",
      "2021/06/29 17:11:39 Python Version found is Python 3.7.1\n",
      "\n",
      "2021/06/29 17:11:39 Returning Python Version as 3.7\n",
      "2021/06/29 17:11:39 sshd inside container not required for job, skipping setup.\n",
      "2021/06/29 17:11:40 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/06/29 17:11:40 App Insight Client has already been closed\n",
      "2021/06/29 17:11:40 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-06-29T17:11:40Z Starting docker container succeeded.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/06/29 17:11:46 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/06/29 17:11:46 Version: 3.0.01632.0003 Branch: .SourceBranch Commit: 4b96fb0\n",
      "2021/06/29 17:11:46 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/06/29 17:11:46 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "[2021-06-29T17:11:46.504157] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['pipeline/register_model_step.py', '--model_name', 'dog_clf_model', '--step_input', '/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/b0462b01-c067-44d6-b2e2-1963cfde2b66/mounts/workspaceblobstore/azureml/14c90a42-b648-4c62-b401-838b149670cc/pipeline_data'])\n",
      "Script type = None\n",
      "[2021-06-29T17:11:47.220934] Entering Run History Context Manager.\n",
      "[2021-06-29T17:11:48.126807] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/b0462b01-c067-44d6-b2e2-1963cfde2b66/wd/azureml/b0462b01-c067-44d6-b2e2-1963cfde2b66\n",
      "[2021-06-29T17:11:48.127045] Preparing to call script [pipeline/register_model_step.py] with arguments:['--model_name', 'dog_clf_model', '--step_input', '/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/b0462b01-c067-44d6-b2e2-1963cfde2b66/mounts/workspaceblobstore/azureml/14c90a42-b648-4c62-b401-838b149670cc/pipeline_data']\n",
      "[2021-06-29T17:11:48.127151] After variable expansion, calling script [pipeline/register_model_step.py] with arguments:['--model_name', 'dog_clf_model', '--step_input', '/mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/b0462b01-c067-44d6-b2e2-1963cfde2b66/mounts/workspaceblobstore/azureml/14c90a42-b648-4c62-b401-838b149670cc/pipeline_data']\n",
      "\n",
      "Getting registration parameters\n",
      "2021/06/29 17:11:51 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "Loading model from /mnt/batch/tasks/shared/LS_root/jobs/mlopstemplatewsbfdc24/azureml/b0462b01-c067-44d6-b2e2-1963cfde2b66/mounts/workspaceblobstore/azureml/14c90a42-b648-4c62-b401-838b149670cc/pipeline_data\n",
      "BuildId tag not found on parent run.\n",
      "Tags present: {'azureml.pipelineid': 'b6216aa0-5fee-44d8-b064-98cd8f278ab6', 'azureml.pipelineComponent': 'pipelinerun', 'trigger': 'jupyter notebook', 'model_architecture': 'transfer-learning with ResNext-50', 'dataset_id': 'dbcee43d-69a3-4f3e-b579-776251e0133e'}\n",
      "BuildUri tag not found on parent run.\n",
      "Tags present: {'azureml.pipelineid': 'b6216aa0-5fee-44d8-b064-98cd8f278ab6', 'azureml.pipelineComponent': 'pipelinerun', 'trigger': 'jupyter notebook', 'model_architecture': 'transfer-learning with ResNext-50', 'dataset_id': 'dbcee43d-69a3-4f3e-b579-776251e0133e'}\n",
      "Registering model dog_clf_model\n",
      "Model registered: dog_clf_model \n",
      "Model Description: None \n",
      "Model Version: 2\n",
      "\n",
      "\n",
      "[2021-06-29T17:11:57.592296] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "4 items cleaning up...\n",
      "Cleanup took 0.31569480895996094 seconds\n",
      "[2021-06-29T17:11:58.086492] Finished context manager injector.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt\n",
      "===============================================================================================================\n",
      "[2021-06-29T17:12:03.564692] Entering job release\n",
      "[2021-06-29T17:12:04.888245] Starting job release\n",
      "[2021-06-29T17:12:04.888989] Logging experiment finalizing status in history service.\n",
      "[2021-06-29T17:12:04.889388] job release stage : upload_datastore starting...Starting the daemon thread to refresh tokens in background for process with pid = 214\n",
      "\n",
      "[2021-06-29T17:12:04.889926] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-06-29T17:12:04.890184] job release stage : execute_job_release starting...\n",
      "[2021-06-29T17:12:04.893356] job release stage : copy_batchai_cached_logs starting...[2021-06-29T17:12:04.893684] Entering context manager injector.\n",
      "[2021-06-29T17:12:04.893740] job release stage : copy_batchai_cached_logs completed...\n",
      "\n",
      "[2021-06-29T17:12:04.955940] job release stage : upload_datastore completed...\n",
      "[2021-06-29T17:12:05.021314] job release stage : send_run_telemetry starting...\n",
      "[2021-06-29T17:12:05.064837] get vm size and vm region successfully.\n",
      "[2021-06-29T17:12:05.073040] get compute meta data successfully.\n",
      "[2021-06-29T17:12:05.131995] job release stage : execute_job_release completed...\n",
      "[2021-06-29T17:12:05.322769] post artifact meta request successfully.\n",
      "[2021-06-29T17:12:05.353049] upload compute record artifact successfully.\n",
      "[2021-06-29T17:12:05.353098] job release stage : send_run_telemetry completed...\n",
      "[2021-06-29T17:12:05.353251] Job release is complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StepRun(Register Model ) Execution Summary\n",
      "===========================================\n",
      "StepRun( Register Model  ) Status: Finished\n",
      "{'runId': 'b0462b01-c067-44d6-b2e2-1963cfde2b66', 'target': 'gpu-cluster', 'status': 'Completed', 'startTimeUtc': '2021-06-29T17:06:30.080675Z', 'endTimeUtc': '2021-06-29T17:12:17.282622Z', 'properties': {'azureml.git.repository_uri': 'https://github.com/sebastianbirk/pytorch-mlops-template-azure-ml.git', 'mlflow.source.git.repoURL': 'https://github.com/sebastianbirk/pytorch-mlops-template-azure-ml.git', 'azureml.git.branch': 'develop', 'mlflow.source.git.branch': 'develop', 'azureml.git.commit': '24ee5abcfc13dfd6c7da3ede3b9f3013132587b1', 'mlflow.source.git.commit': '24ee5abcfc13dfd6c7da3ede3b9f3013132587b1', 'azureml.git.dirty': 'True', 'ContentSnapshotId': 'a77d3106-296d-4662-949a-a22a25b989ae', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'bbcab9ab-1240-4388-90d3-58f5c1ad3518', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '5c4eed1a', 'azureml.pipelinerunid': 'b360d7c1-5d4d-4cf6-9147-6c69fc33c36e', 'azureml.pipelineid': 'b6216aa0-5fee-44d8-b064-98cd8f278ab6', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'dbcee43d-69a3-4f3e-b579-776251e0133e'}, 'consumptionDetails': {'type': 'Reference'}}], 'outputDatasets': [{'identifier': {'savedId': 'dbcee43d-69a3-4f3e-b579-776251e0133e', 'registeredId': '6fcf19eb-d446-4acd-85e5-de8064af033c', 'registeredVersion': '1'}, 'outputType': 'Reference', 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'data/stanford_dogs')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"dbcee43d-69a3-4f3e-b579-776251e0133e\",\n",
      "    \"name\": \"stanford_dogs_dataset\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"Stanford Dogs Dataset containing training, validation and test data\",\n",
      "    \"tags\": {\n",
      "      \"file_format\": \"jpg\",\n",
      "      \"file_path_example\": \"data/stanford_dogs/val/n02085620-Chihuahua/n02085620_1152.jpg\"\n",
      "    },\n",
      "    \"workspace\": \"Workspace.create(name='mlopstemplatewsbfdc24', subscription_id='e58a23da-421e-4b52-99d5-e615f2f8be41', resource_group='mlopstemplaterg')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'pipeline/register_model_step.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_name', '$AML_PARAMETER_model_name', '--step_input', '$AZUREML_DATAREFERENCE_pipeline_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpu-cluster', 'dataReferences': {'pipeline_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/14c90a42-b648-4c62-b401-838b149670cc/pipeline_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'dogs_clf_train_env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge', 'pytorch'], 'dependencies': ['joblib=0.13.2', 'matplotlib=3.3.3', 'pip=21.0.1', 'python=3.7.1', 'python-dotenv=0.8.2', 'pytorch::pytorch=1.7.0', 'pytorch::torchvision=0.8.1', 'scipy=1.6.0', 'tqdm=4.38.0', {'pip': ['azure-cli==2.3.1', 'azureml-core==1.20.0', 'azureml-defaults', 'azureml-sdk', 'azureml-widgets']}], 'name': 'azureml_7e4004f9dc5d19006a729afa49674785'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20201113.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': None, 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_model_name': 'dog_clf_model'}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/azureml-logs/55_azureml-execution-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt?sv=2019-02-02&sr=b&sig=MEff700AJL2jYn%2B2zdfuguedQyk3zCwnL7wTT3zCsyI%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'azureml-logs/65_job_prep-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/azureml-logs/65_job_prep-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt?sv=2019-02-02&sr=b&sig=3JWhxRyNkIYn4WtQB0mfXqjzJtxFPUQ16LfdN108Bag%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=c9FAx%2FVRHoQb4Hn1jrMlCmiPNP7qtK%2FO9dhituFQ1iw%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'azureml-logs/75_job_post-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/azureml-logs/75_job_post-tvmps_c9a77e93a71e9584e7235b2523fef9602788c1f007e7504932dc8fae63a1ca91_d.txt?sv=2019-02-02&sr=b&sig=88PVfsVXzl4U7Pf80xNWtyEDTRbq8VB6Dw7xrNOxLFw%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'azureml-logs/process_info.json': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=qTI0LIEQIhYPtO0NLicgHXVBEBlv7ihExEfwiO0K2HA%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'azureml-logs/process_status.json': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=X%2FYQrijENCrQFFEsCxMVzmfmAcH3VjqBYO%2Feuw34DJ0%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'logs/azureml/119_azureml.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/logs/azureml/119_azureml.log?sv=2019-02-02&sr=b&sig=xBuhHKloKejs5TaxXff2M%2BWNr2qdxL1BAQIzsAyJvfE%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'logs/azureml/dataprep/python_span_1391c4ac-2917-4df0-b9ac-e6dce53db29f.jsonl': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/logs/azureml/dataprep/python_span_1391c4ac-2917-4df0-b9ac-e6dce53db29f.jsonl?sv=2019-02-02&sr=b&sig=cvIqmT%2FNARjakhnxf8ZlxmrqbmC3UD27N4qKO64Mz7Y%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'logs/azureml/dataprep/python_span_16ba7580-fda4-4452-aa71-d1582cf6dcd0.jsonl': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/logs/azureml/dataprep/python_span_16ba7580-fda4-4452-aa71-d1582cf6dcd0.jsonl?sv=2019-02-02&sr=b&sig=CzMEp1eoxCJun%2FmEGttX7OKdKJUFKnX0Keviy76WWfk%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'logs/azureml/dataprep/python_span_c798c918-7745-4fe5-bbad-232f38523cc4.jsonl': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/logs/azureml/dataprep/python_span_c798c918-7745-4fe5-bbad-232f38523cc4.jsonl?sv=2019-02-02&sr=b&sig=%2B7ElvnbN4bxXiNGJfoDVoMU3hg%2F4RDmqnuLK%2BX9atU0%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=ytTo1LB1H6C4ou%2FAkiYNvfzuAMFoBHaQ2QhaC%2FjrQJQ%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=Qpssz0T4mFn0FkCBzXIt9BZf1xSRqOJAuemJ0BPpVJU%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=qGKutbadC7dkdUeL1%2B44aAvV0hl86T1gmvoxu5kf8BU%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=uUFiL3fZIhPEsEyjEgpDPpM9um8t0l5tQu%2BbRUaqoKc%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b0462b01-c067-44d6-b2e2-1963cfde2b66/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=yz2hI8MEPDMBaCTyIEZ%2FtcZAGwJnZJYBDBE7uE1oLBw%3D&st=2021-06-29T17%3A02%3A10Z&se=2021-06-30T01%3A12%3A10Z&sp=r'}, 'submittedBy': 'Sebastian Birk'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'b360d7c1-5d4d-4cf6-9147-6c69fc33c36e', 'status': 'Completed', 'startTimeUtc': '2021-06-29T15:01:00.125885Z', 'endTimeUtc': '2021-06-29T17:12:20.728765Z', 'properties': {'azureml.git.repository_uri': 'https://github.com/sebastianbirk/pytorch-mlops-template-azure-ml.git', 'mlflow.source.git.repoURL': 'https://github.com/sebastianbirk/pytorch-mlops-template-azure-ml.git', 'azureml.git.branch': 'develop', 'mlflow.source.git.branch': 'develop', 'azureml.git.commit': '24ee5abcfc13dfd6c7da3ede3b9f3013132587b1', 'mlflow.source.git.commit': '24ee5abcfc13dfd6c7da3ede3b9f3013132587b1', 'azureml.git.dirty': 'True', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"model_name\":\"dog_clf_model\",\"caller_run_id\":\"none\",\"dataset_name\":\"stanford_dogs_dataset\",\"dataset_version\":\"1\",\"data_file_path\":\"none\"}', 'azureml.pipelineid': 'b6216aa0-5fee-44d8-b064-98cd8f278ab6'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b360d7c1-5d4d-4cf6-9147-6c69fc33c36e/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=t%2B3ZFIc5hzAgXG1nC2KsxkBHc1RHkrozUJlwWkRi0Uw%3D&st=2021-06-29T17%3A02%3A27Z&se=2021-06-30T01%3A12%3A27Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b360d7c1-5d4d-4cf6-9147-6c69fc33c36e/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=c1wi77rE%2F4a%2BbogCKdm89rdI%2Bpfy1E0mMLU%2Ftnqi86A%3D&st=2021-06-29T17%3A02%3A27Z&se=2021-06-30T01%3A12%3A27Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopstemplatesabfdc24.blob.core.windows.net/azureml/ExperimentRun/dcid.b360d7c1-5d4d-4cf6-9147-6c69fc33c36e/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=gmQidTPZbSBEpqqbx6AnuDzQ9q1MLcvyYVTu02vfENo%3D&st=2021-06-29T17%3A02%3A27Z&se=2021-06-30T01%3A12%3A27Z&sp=r'}, 'submittedBy': 'Sebastian Birk'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait for completion of the run and show output log\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to delete the compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_target.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dogs_clf_dev_env",
   "language": "python",
   "name": "dogs_clf_dev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
