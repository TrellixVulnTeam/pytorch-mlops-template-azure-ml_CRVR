{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE OF CONTENTS:\n",
    "---\n",
    "* [Notebook Summary](#Notebook-Summary)\n",
    "* [Setup](#Setup)\n",
    "    * [Custom Vision](#Custom-Vision)\n",
    "* [Upload and Tag Data](#Upload-and-Tag-Data)\n",
    "* [Model Training](#Model-Training)\n",
    "* [Publish Endpoint](#Publish-Endpoint)\n",
    "* [Model Evaluation](#Model-Evaluation)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will create a new project in a Custom Vision Azure Cognitive Services resource, upload the stanford dogs training set to it (including class tags), train a model using advanced training and finally evaluate the trained model on the stanford dogs test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append parent directory to sys path to be able to import created modules from src directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(\"\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically reload modules when changes are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Import created modules\n",
    "from src.utils import EnvVariables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_variables = EnvVariables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create API key credentials for trainer and predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_credentials = ApiKeyCredentials(in_headers={\"Training-key\": env_variables.custom_vision_training_key})\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": env_variables.custom_vision_prediction_key})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Custom Vision training and prediction clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomVisionTrainingClient(env_variables.custom_vision_endpoint, training_credentials)\n",
    "predictor = CustomVisionPredictionClient(env_variables.custom_vision_endpoint, prediction_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Custom Vision project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Custom Vision project...\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating Custom Vision project...\")\n",
    "project = trainer.create_project(name=env_variables.custom_vision_project_name, classification_type=\"Multiclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload and Tag Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the training data to the Custom Vision project and tag each image according to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding images to Custom Vision project...\n",
      "====================\n",
      "New current tag: n02085620-Chihuahua\n",
      "Upload new batch\n",
      "Image 1 of current batch - Image status:  OK\n"
     ]
    }
   ],
   "source": [
    "base_image_location_train = \"../data/train\"\n",
    "\n",
    "print(\"Adding images to Custom Vision project...\")\n",
    "\n",
    "for root, dirs, files in os.walk(base_image_location_train):\n",
    "    for i, file in enumerate(files):\n",
    "        # For first file in current directory create the class tag in the project\n",
    "        if i == 0:\n",
    "            print(\"=\" * 20)\n",
    "            print(f\"New current tag: {root.split('/')[-1]}\")\n",
    "            current_tag = trainer.create_tag(project.id, root.split(\"/\")[-1])\n",
    "            # Initialize empty image list\n",
    "            image_list = []\n",
    "           \n",
    "        # Read current file (image) and append it to the image_list\n",
    "        with open(os.path.join(root, file), \"rb\") as image_contents:\n",
    "            image_list.append(ImageFileCreateEntry(name=file, contents=image_contents.read(), tag_ids=[current_tag.id]))\n",
    "            \n",
    "        # For every 32 files (images) or at the last file (image) of the current directory,\n",
    "        # upload the batch of images to the project \n",
    "        if (i % 31 == 0 and i != 0) or i == (len(files)-1):\n",
    "            print(f\"Upload new batch\")\n",
    "            upload_result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=image_list))\n",
    "            if not upload_result.is_batch_successful:\n",
    "                print(\"Image batch upload failed.\")\n",
    "            for j, image in enumerate(upload_result.images):\n",
    "                print(f\"Image {j+1} of current batch - Image status: \", image.status)\n",
    "            image_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "====================\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d64c0852e80d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Training status: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print (\"Start training...\")\n",
    "print(\"=\" * 20)\n",
    "iteration = trainer.train_project(project.id, training_type=\"Advanced\", reserved_budget_in_hours=2)\n",
    "\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publish Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iteration is now trained. Publish it to the project endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint published!\n"
     ]
    }
   ],
   "source": [
    "trainer.publish_iteration(project.id,\n",
    "                          iteration.id,\n",
    "                          env_variables.custom_vision_publish_iteration_name,\n",
    "                          env_variables.custom_vision_prediction_resource_id)\n",
    "\n",
    "print (\"Endpoint published!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model on test set...\n",
      "Test Accuracy: 79.4988344988345%\n"
     ]
    }
   ],
   "source": [
    "base_image_location_test = \"../data/test\"\n",
    "\n",
    "correct_pred_list = []\n",
    "print(\"Testing model on test set...\")\n",
    "\n",
    "for root, dirs, files in os.walk(base_image_location_test):\n",
    "    for i, file in enumerate(files): \n",
    "        with open(os.path.join(root, file), \"rb\") as image_contents:\n",
    "            results = predictor.classify_image(\n",
    "                project.id, env_variables.custom_vision_publish_iteration_name, image_contents.read())\n",
    "            \n",
    "            # Display the results.\n",
    "            correct_pred_list.append(results.predictions[0].tag_name == root.split(\"/\")[-1])\n",
    "\n",
    "test_accuracy = (np.sum(correct_pred_list)/len(correct_pred_list))\n",
    "print(f\"Test Accuracy: {test_accuracy*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dogs_clf_dev_env",
   "language": "python",
   "name": "dogs_clf_dev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
