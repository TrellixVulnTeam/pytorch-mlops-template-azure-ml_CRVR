{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE OF CONTENTS:\n",
    "---\n",
    "* [Setup](#Setup)\n",
    "    * [Connect to Workspace](#Connect-to-Workspace)\n",
    "* [Data](#Data)\n",
    "    * [Download Data](#Download-Data)\n",
    "    * [Explore Data](#Explore-Data)\n",
    "    * [Upload Data](#Upload-Data)\n",
    "    * [Create and Register AML Dataset](#Create-and-Register-AML-Dataset)\n",
    "* [Compute Target](#Compute-Target)\n",
    "* [Training Artifacts](#Training-Artifacts)\n",
    "* [Training Environment](#Development-Environment)\n",
    "* [Compute Target](#Compute-Target)\n",
    "* [Development Environment](#Development-Environment)\n",
    "* [Experiment & Run Configuration](#Experiment-&-Run-Configuration)\n",
    "    * [Option 1: Normal Script Run](#Option-1:-Normal-Script-Run)\n",
    "    * [Option 2: Hyperdrive Run](#Option-2:-Hyperdrive-Run)\n",
    "* [Run Monitoring](#Run-Monitoring)\n",
    "* [Model Registration](#Model-Registration)\n",
    "    * [Model Download](#Model-Download)\n",
    "* [Resource Clean Up](#Resource-Clean-Up)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append parent directory to sys path to be able to import created modules from src directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import azureml.core\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import uuid\n",
    "\n",
    "from azureml.core.authentication import MsiAuthentication\n",
    "from azureml.core import Dataset, Environment, Experiment, Keyvault, Model, ScriptRunConfig, Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.model import InferenceConfig \n",
    "from azureml.train.hyperdrive import BanditPolicy, HyperDriveConfig, PrimaryMetricGoal, RandomParameterSampling\n",
    "from azureml.train.hyperdrive import choice, uniform\n",
    "from azureml.widgets import RunDetails\n",
    "from torchvision import datasets\n",
    "\n",
    "# Import created modules\n",
    "from src.training.data_utils import download_data, load_data, imshow\n",
    "\n",
    "print(f\"azureml.core version: {azureml.core.VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically reload modules when changes are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training directory. This directory will contain all artifacts needed for model training. For AML remote training this directory will be copied to the remote compute at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = os.path.join(os.getcwd(), \"../src/training\")\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "print(f\"Training folder {training_folder} has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory to store the training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.getcwd(), \"../data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "print(f\"Data folder {data_folder} has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to connect and communicate with the Azure Machine Learning (AML) workspace, a workspace object needs to be instantiated using the Azure ML SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the AML workspace.\n",
    "# For alternative connection options see the aml_snippets directory.\n",
    "msi_auth = MsiAuthentication()\n",
    "\n",
    "ws = Workspace(subscription_id=\"bf088f59-f015-4332-bd36-54b988be7c90\",\n",
    "               resource_group=\"amlbrikserg\",\n",
    "               workspace_name=\"amlbriksews\",\n",
    "               auth=msi_auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this template, a dataset provided in Azure Open Data Storage (https://azureopendatastorage.blob.core.windows.net/testpublic/temp/fowl_data.zip) is used to build a binary classification model that can classify chickens and turkeys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a script with utility functions to download, load and display the data (this script already exists in the src folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $training_folder/data_utils.py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import urllib\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "def download_data():\n",
    "    \"\"\"\n",
    "    Download and extract the data needed for model training.\n",
    "    :return data_dir: directory where the data is stored\n",
    "    \"\"\"\n",
    "    \n",
    "    # download data\n",
    "    print(\"Downloading archive file...\")\n",
    "    archive_file = \"../data/fowl_data.zip\"\n",
    "    download_url = \"https://azureopendatastorage.blob.core.windows.net/testpublic/temp/fowl_data.zip\"\n",
    "    urllib.request.urlretrieve(download_url, filename=archive_file)\n",
    "\n",
    "    # extract files\n",
    "    with ZipFile(archive_file, \"r\") as zip:\n",
    "        print(\"Extracting files...\")\n",
    "        zip.extractall(\"../data\")\n",
    "        print(\"Finished extracting!\")\n",
    "        data_dir = os.path.join(\"../data\", zip.namelist()[0])\n",
    "\n",
    "    # delete zip file\n",
    "    os.remove(archive_file)\n",
    "    return data_dir\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\"\n",
    "    Load the train/val data.\n",
    "    :return (dataloaders, dataset_sizes, class_names):\n",
    "        dataloaders: dictionary containing pytorch train and validation dataloaders\n",
    "        dataset_sizes: dictionary containing the size of the training and validation datasets\n",
    "        class_names: list containing all class names\n",
    "    \"\"\"\n",
    "\n",
    "    # Data augmentation and normalization for training\n",
    "    # Just normalization for validation\n",
    "    data_transforms = {\n",
    "        \"train\": transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        \"val\": transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                              data_transforms[x])\n",
    "                      for x in [\"train\", \"val\"]}\n",
    "    \n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                                  shuffle=True, num_workers=4)\n",
    "                   for x in [\"train\", \"val\"]}\n",
    "    \n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n",
    "    \n",
    "    class_names = image_datasets[\"train\"].classes\n",
    "\n",
    "    return dataloaders, dataset_sizes, class_names\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\"\n",
    "    Unnormalize an image batch retrieved from a dataloader and plot the batch\n",
    "    \"\"\"\n",
    "    \n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) # transpose dimensions from Pytorch format to default numpy format\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def preprocess_image(image_file):\n",
    "    \"\"\"\n",
    "    Preprocess an input image.\n",
    "    :param image_file: Path to the input image\n",
    "    :return image.numpy(): preprocessed image as numpy array\n",
    "    \"\"\"\n",
    "    \n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_file)\n",
    "    image = data_transforms(image).float()\n",
    "    image = image.clone().detach()\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    return image.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from https://azureopendatastorage.blob.core.windows.net/testpublic/temp/fowl_data.zip to the AML Compute Instance / local compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fowl_data_directory = download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloaders to load the data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders, dataset_sizes, class_names = load_data(fowl_data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first batch of 4 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some random validation images\n",
    "dataiter = iter(dataloaders[\"val\"])\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# Print labels\n",
    "print(\" \".join(\"%11s\" % class_names[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the data to the default AML datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(src_dir=\"../data/fowl_data\", target_path=\"data/fowl_data\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Register AML Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the data as a dataset in the AML workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset object from datastore location\n",
    "dataset = Dataset.File.from_files(path=(datastore, \"data/fowl_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the dataset\n",
    "dataset = dataset.register(workspace=ws,\n",
    "                           name=\"fowl-dataset\",\n",
    "                           description=\"fowl dataset containing training and validation data\",\n",
    "                           create_new_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a remote compute target to run experiments on. The below code will first check whether a compute target with name `cluster_name` already exists and if it does, it will use that instead of creating a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a name for the CPU cluster\n",
    "cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\", # CPU\n",
    "                                                           # vm_size='STANDARD_NC6', # GPU\n",
    "                                                           max_nodes=4,\n",
    "                                                           idle_seconds_before_scaledown=2400)\n",
    "    \n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use get_status() to get a detailed status for the current cluster\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A training script is created in the aml_training folder. This script will be executed by the remote compute. The training script uses transfer learning to train a pretrained ResNet18 model on the fowl dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $training_folder/train.py\n",
    "# Copyright (C) 2017, PyTorch contributors\n",
    "# Adapted from https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "# Import libraries\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import urllib\n",
    "from azureml.core import Run\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Import own modules\n",
    "from data_utils import load_data\n",
    "# from model import Net\n",
    "\n",
    "# Get AML Run object\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "def train_model(model: torchvision.models,\n",
    "                criterion: torch.nn.modules.loss,\n",
    "                optimizer: torch.optim,\n",
    "                scheduler: torch.optim.lr_scheduler,\n",
    "                num_epochs: int,\n",
    "                dataloaders: dict,\n",
    "                dataset_sizes: dict) -> torchvision.models:\n",
    "    \"\"\"\n",
    "    Train the model and track training and validation loss and accuracy.\n",
    "    :param model: pretrained model which will be trained further\n",
    "    :param criterion: torch loss function\n",
    "    :param optimizer: torch optimizer\n",
    "    :param scheduler: torch learning rate scheduler\n",
    "    :param num_epochs: number of epochs to train the model\n",
    "    :param dataloaders: dictionary of torch dataloaders\n",
    "    :param dataset_sizes: dictionary with lengths of the training and val set\n",
    "    :return model: pretrained model with tuned final fully connected layer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Leverage GPU if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load in weights of model\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # Initialize best_acc\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"=\" * 20)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"=\" * 20)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train() # Set model to training mode\n",
    "            else:\n",
    "                model.eval() # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_correct_preds = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                # Track history only if in training phase\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass, gradient optimization and learning rate update\n",
    "                    # only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step() \n",
    "\n",
    "                # Calculate statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_correct_preds += torch.sum(preds == labels.data)\n",
    "                \n",
    "\n",
    "            # Average loss and accuracy over examples\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_correct_preds.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "            \n",
    "            # Log the epoch validation loss and accuracy to AML run\n",
    "            if phase == \"train\":\n",
    "                run.log(\"train_loss\", np.float(epoch_loss))\n",
    "                run.log(\"train_acc\", np.float(epoch_acc))\n",
    "                \n",
    "            if phase == \"val\":\n",
    "                run.log(\"val_loss\", np.float(epoch_loss))\n",
    "                run.log(\"val_acc\", np.float(epoch_acc))\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "                # Log the best val accuracy to AML run\n",
    "                run.log(\"best_val_acc\", np.float(best_acc))\n",
    "            \n",
    "            if phase == \"train\":\n",
    "                print(\"-\" * 20)\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"Training completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s.\")\n",
    "    print(f\"Best Val Acc: {best_acc:4f}\")\n",
    "          \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_weights)\n",
    "          \n",
    "    return model\n",
    "\n",
    "\n",
    "def fine_tune_model(num_epochs: int,\n",
    "                    num_classes: int,\n",
    "                    dataloaders: dict,\n",
    "                    dataset_sizes: dict,\n",
    "                    learning_rate: float,\n",
    "                    momentum: float) -> torchvision.models:\n",
    "    \"\"\"\n",
    "    Load a pretrained model and reset the final fully connected layer.\n",
    "    :param num_epochs: number of epochs to train the model\n",
    "    :param num_classes: number of target classes \n",
    "        (supports binary and multiclass classification)\n",
    "    :param dataloaders: dictionary of torch dataloaders\n",
    "    :param dataset_sizes: dictionary with lengths of the training and val set\n",
    "    :param learning_rate: learning rate hyperparameter\n",
    "    :param momentum: momentum hyperparameter\n",
    "    :return model: pretrained model with tuned final fully connected layer\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "    print(\"START TRAINING\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    # Log the hyperparameter metrics to the AML run\n",
    "    run.log(\"lr\", learning_rate)\n",
    "    run.log(\"momentum\", momentum)\n",
    "\n",
    "    # Load pretrained model and reset final fully connected layer to have num_classes output neurons\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # Leverage GPU if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    # Specify loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Create SGD optimizer to optimize all parameters\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(),\n",
    "                             lr=learning_rate,\n",
    "                             momentum=momentum)\n",
    "                            \n",
    "    # Create scheduler to decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft,\n",
    "                                           step_size=7,\n",
    "                                           gamma=0.1)\n",
    "    \n",
    "    # Start model training\n",
    "    model = train_model(model_ft, criterion, optimizer_ft,\n",
    "                        exp_lr_scheduler, num_epochs, dataloaders,\n",
    "                        dataset_sizes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "    \n",
    "    # Retrieve command-line arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data_path\", type=str, help=\"Path where the images are stored\")\n",
    "    parser.add_argument(\"--num_epochs\", type=int, default=25, help=\"Number of epochs to train\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, help=\"Output directory\")\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.001, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--momentum\", type=float, default=0.9, help=\"Momentum\")\n",
    "    args = parser.parse_args()\n",
    "          \n",
    "    # Load training and validation data\n",
    "    dataloaders, dataset_sizes, class_names = load_data(args.data_path)\n",
    "        \n",
    "    # Train the model\n",
    "    model = fine_tune_model(num_epochs=args.num_epochs,\n",
    "                            num_classes=len(class_names),\n",
    "                            dataloaders=dataloaders,\n",
    "                            dataset_sizes=dataset_sizes,\n",
    "                            learning_rate=args.learning_rate,\n",
    "                            momentum=args.momentum)\n",
    "    \n",
    "    # Save the model\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    torch.save(model, os.path.join(args.output_dir, \"model.pt\"))\n",
    "    print(\"=\" * 20)\n",
    "    print(f\"Model saved in {args.output_dir}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile $training_folder/model.py\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 16 * 5 * 5)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training script locally for 2 epochs for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../src/training/train.py --data_path ../data/fowl_data --num_epochs=2 --output_dir=\"../outputs\" --learning_rate 0.01 --momentum 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the environment that has been registered as part of the **01_environment_creation** notebook and use it for remote training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"pytorch-aml-env\"\n",
    "env = Environment.get(workspace=ws, name=env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment & Run Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the training artifacts are prepared, a model can be trained on the remote compute cluster. You can take advantage of Azure compute to leverage GPUs to cut down your training time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the experiment\n",
    "experiment = Experiment(workspace=ws, \n",
    "                        name=\"fowl-pytorch\")\n",
    "\n",
    "experiment.tag(\"model_architecture\", \"transfer-learning with resnet18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Normal Script Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variable to identify run type for logic later in the notebook\n",
    "run_type = \"script_run\"\n",
    "\n",
    "# Create the script run configuration\n",
    "src_config = ScriptRunConfig(source_directory=\"../src/training\",\n",
    "                             script=\"train.py\",\n",
    "                             compute_target=compute_target,\n",
    "                             arguments=[\n",
    "                                 \"--data_path\", dataset.as_named_input(\"input\").as_mount(),\n",
    "                                 \"--num_epochs\", 20,\n",
    "                                 \"--output_dir\", \"outputs\",\n",
    "                                 \"--learning_rate\", 0.01,\n",
    "                                 \"--momentum\", 0.9])\n",
    "\n",
    "src_config.run_config.environment = env\n",
    "\n",
    "# Start the Script Run\n",
    "run = experiment.submit(src_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Hyperdrive Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters can be tuned using AML's hyperdrive capability.\n",
    "\n",
    "The initial learning rate is tuned. The training script can contain a LR schedule to decay the learning rate every several epochs starting from that initial learning rate.\n",
    "\n",
    "Random sampling is used to try different configuration sets of hyperparameters to maximize the primary metric, the best validation accuracy (best_val_acc).\n",
    "\n",
    "An early termination policy is specified to early terminate poorly performing runs. The BanditPolicy is used, which will terminate any run that doesn't fall within the slack factor of the primary evaluation metric. In this template, this policy will be applied every epoch (since the best_val_acc metric is reported every epoch and evaluation_interval=1). The first policy evaluation will be delayed until after the first 10 epochs (delay_evaluation=10). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variable to identify run type for logic later in the notebook\n",
    "run_type = \"hyperdrive_run\"\n",
    "\n",
    "param_sampling = RandomParameterSampling({\n",
    "    \"learning_rate\": uniform(0.0005, 0.005),\n",
    "    \"momentum\": uniform(0.9, 0.99)}\n",
    ")\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=10)\n",
    "\n",
    "# Create the script run configuration\n",
    "src_config = ScriptRunConfig(source_directory=\"../src/training\",\n",
    "                             script=\"train.py\",\n",
    "                             compute_target=compute_target,\n",
    "                             arguments=[\n",
    "                                 \"--data_path\", dataset.as_named_input(\"input\").as_mount(),\n",
    "                                 \"--num_epochs\", 20,\n",
    "                                 \"--output_dir\", \"outputs\",\n",
    "                                 \"--learning_rate\", 0.01,\n",
    "                                 \"--momentum\", 0.9])\n",
    "\n",
    "src_config.run_config.environment = env\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(run_config=src_config,\n",
    "                                     hyperparameter_sampling=param_sampling, \n",
    "                                     policy=early_termination_policy,\n",
    "                                     primary_metric_name=\"best_val_acc\",\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=4,\n",
    "                                     max_concurrent_runs=2)\n",
    "\n",
    "# Start the Hyperdrive Run\n",
    "run = experiment.submit(hyperdrive_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get portal URL\n",
    "run.get_portal_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve best child run\n",
    "if run_type == \"script_run\":\n",
    "    best_child_run = run\n",
    "elif run_type == \"hyperdrive_run\":\n",
    "    best_child_run = run.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check run metrics, details and file names\n",
    "best_child_run_metrics = best_child_run.get_metrics()\n",
    "best_child_run_details = best_child_run.get_details()\n",
    "best_child_run_file_names = best_child_run.get_file_names()\n",
    "\n",
    "\n",
    "print(best_child_run_metrics)\n",
    "print(\"==========================\")\n",
    "print(best_child_run_details)\n",
    "print(\"==========================\")\n",
    "print(best_child_run_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Run is:\")\n",
    "\n",
    "if run_type == \"script_run\":\n",
    "    print(f\"Validation accuracy: {best_child_run_metrics['best_val_acc'][-1]}\")\n",
    "elif run_type == \"hyperdrive_run\":\n",
    "    print(f\"Validation accuracy: {best_child_run_metrics['best_val_acc']}\")\n",
    "\n",
    "print(f\"Learning rate: {best_child_run_metrics['lr']}\")\n",
    "print(f\"Momentum: {best_child_run_metrics['momentum']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"outputs/model.pt\"\n",
    "\n",
    "model = best_child_run.register_model(model_name=\"fowl-model\",\n",
    "                                      model_path=model_path,\n",
    "                                      model_framework=Model.Framework.PYTORCH,\n",
    "                                      description=\"fowl model\")\n",
    "\n",
    "print(model.name, model.id, model.version, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_model=True\n",
    "\n",
    "if download_model:\n",
    "    \n",
    "    # Create directory\n",
    "    outputs_folder = os.path.join(os.getcwd(), \"../outputs\")\n",
    "    os.makedirs(outputs_folder, exist_ok=True)\n",
    "    print(f\"Outputs folder {outputs_folder} has been created.\")\n",
    "    \n",
    "    # Download model artifact\n",
    "    best_child_run.download_file(name=model_path, output_file_path=\"../outputs/model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target.delete()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "samkemp"
   }
  ],
  "categories": [
   "tutorials",
   "get-started-day1"
  ],
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "notice": "Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
