{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE OF CONTENTS:\n",
    "---\n",
    "* [Setup](#Setup)\n",
    "    * [Connect to Workspace](#Connect-to-Workspace)\n",
    "    * [Pipeline Configuration](#Pipeline-Configuration)\n",
    "    * [Pipeline Run](#Pipeline-Run)\n",
    "    * [Download & Inspect Pipeline Output](#Download-&-Inspect-Pipeline-Output)\n",
    "* [Publish the Pipeline](#Publish-the-Pipeline)\n",
    "* [Resource Clean Up](#Resource-Clean-Up)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tempfile\n",
    "from azureml.core import Environment, Experiment, Workspace\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to connect and communicate with the Azure Machine Learning (AML) workspace, a workspace object needs to be instantiated using the Azure ML SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "# Connect to the AML workspace with interactive authentication.\n",
    "# For alternative connection options (e.g. for automated workloads) see the aml_snippets directory.\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "input_images = Dataset.File.from_files((datastore, \"data/fowl_data/val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = input_images.register(workspace=ws, name=\"batch_scoring_input_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = PipelineData(name=\"scores\", datastore=datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"pytorch-aml-env\"\n",
    "env = Environment.get(workspace=ws, name=env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-01-26T12:11:26.686000+00:00', 'errors': None, 'creationTime': '2021-01-26T06:03:23.831952+00:00', 'modifiedTime': '2021-01-26T06:03:39.858420+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT2400S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
     ]
    }
   ],
   "source": [
    "# Choose a name for the CPU cluster\n",
    "cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\", # CPU\n",
    "                                                           # vm_size='STANDARD_NC6', # GPU\n",
    "                                                           max_nodes=4,\n",
    "                                                           idle_seconds_before_scaledown=2400)\n",
    "    \n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use get_status() to get a detailed status for the current cluster\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a configuration to wrap the inference script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_run_config = ParallelRunConfig(\n",
    "    environment=env,\n",
    "    entry_script=\"batch_score.py\",\n",
    "    source_directory=\"../src/batch_pipeline_deployment\",\n",
    "    output_action=\"append_row\",\n",
    "    append_row_file_name=\"parallel_run_step.txt\",\n",
    "    mini_batch_size=\"20\",\n",
    "    error_threshold=1,\n",
    "    compute_target=compute_target,\n",
    "    process_count_per_node=2,\n",
    "    node_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline step. \n",
    "\n",
    "A pipeline step is an object that encapsulates everything you need for running a pipeline including:\n",
    "* environment and dependency settings\n",
    "* the compute resource to run the pipeline on\n",
    "* input and output data, and any custom parameters\n",
    "* reference to a script or SDK-logic to run during the step\n",
    "\n",
    "There are multiple classes that inherit from the parent class PipelineStep to assist with building a step using certain frameworks and stacks. In this example, a ParallelRunStep class is used to define the step logic using a scoring script.\n",
    "\n",
    "An object reference in the outputs array becomes available as an input for a subsequent pipeline step, for scenarios where there is more than one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "batch_score_step = ParallelRunStep(\n",
    "    name=parallel_step_name,\n",
    "    inputs=[input_images.as_named_input(\"input_images\")],\n",
    "    output=output_dir,\n",
    "    arguments=[\"--model_name\", \"fowl-model\"],\n",
    "    #side_inputs=[label_config],\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    allow_reuse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The first pipeline run takes roughly 15 minutes, as all dependencies must be downloaded, a Docker image is created, and the Python environment is provisioned/created. Running it again takes significantly less time as those resources are reused. However, total run time depends on the workload of your scripts and processes running in each pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batchscoring-202102042022 [fa1ef946][c3b5010f-9ecf-482b-acf5-203ebea80a59], (This step will run and generate new outputs)\n",
      "Using data reference input_images_0 for StepId [af93fb0d][fe975c3f-a357-402c-85cd-cc8e813c57fa], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted PipelineRun 4e0c7105-28c2-4f1f-9898-bbd45e6b9332\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Tutorial-Batch-Scoring/runs/4e0c7105-28c2-4f1f-9898-bbd45e6b9332?wsid=/subscriptions/bf088f59-f015-4332-bd36-54b988be7c90/resourcegroups/amlbrikserg/workspaces/amlbriksews\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[batch_score_step])\n",
    "pipeline_run = Experiment(ws, \"Tutorial-Batch-Scoring\").submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 4e0c7105-28c2-4f1f-9898-bbd45e6b9332\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Tutorial-Batch-Scoring/runs/4e0c7105-28c2-4f1f-9898-bbd45e6b9332?wsid=/subscriptions/bf088f59-f015-4332-bd36-54b988be7c90/resourcegroups/amlbrikserg/workspaces/amlbriksews\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: bd97e264-18cf-4a2d-b471-6001a641299a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Tutorial-Batch-Scoring/runs/bd97e264-18cf-4a2d-b471-6001a641299a?wsid=/subscriptions/bf088f59-f015-4332-bd36-54b988be7c90/resourcegroups/amlbrikserg/workspaces/amlbriksews\n",
      "StepRun( batchscoring-202102042022 ) Status: NotStarted\n",
      "StepRun( batchscoring-202102042022 ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d.txt\n",
      "========================================================================================================================\n",
      "2021-02-04T21:01:26Z Starting output-watcher...\n",
      "2021-02-04T21:01:26Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-02-04T21:01:27Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-02-04T21:01:27Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_c6f9450edc622673b737209ed4accfa0\n",
      "Digest: sha256:9f25d7590e2707af36af8a89a24d7ce4afda596fbe12058223bb1ffdee6dcaa2\n",
      "Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_c6f9450edc622673b737209ed4accfa0:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_c6f9450edc622673b737209ed4accfa0:latest\n",
      "2021-02-04T21:01:28Z Check if container bd97e264-18cf-4a2d-b471-6001a641299a already exist exited with 0, \n",
      "\n",
      "e1f8537ccaf8468f210c9d3e2a4eb90aad14751ec5bcdc1eeeaeb99c4fa07aa6\n",
      "2021/02/04 21:01:29 Starting App Insight Logger for task:  containerSetup\n",
      "2021/02/04 21:01:29 Version: 3.0.01485.0006 Branch: 2 Commit: a809e28\n",
      "2021/02/04 21:01:29 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/02/04 21:01:29 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/02/04 21:01:29 sshd inside container not required for job, skipping setup.\n",
      "2021/02/04 21:01:30 All App Insights Logs was send successfully\n",
      "2021-02-04T21:01:30Z Starting docker container succeeded.\n",
      "2021-02-04T21:01:50Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-02-04T21:01:50Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_bb7eb2396099509d165438d9e824c159\n",
      "Digest: sha256:802bd745209a2c9136890390b0bc69e11376686708fe72f180a5f90af11afe10\n",
      "Status: Image is up to date for 3d5545b15c4c49548d3823156fa90536.azurecr.io/azureml/azureml_bb7eb2396099509d165438d9e824c159:latest\n",
      "3d5545b15c4c49548d3823156fa90536.azurecr.io/azureml/azureml_bb7eb2396099509d165438d9e824c159:latest\n",
      "2021-02-04T21:01:50Z Check if container bd97e264-18cf-4a2d-b471-6001a641299a already exist exited with 0, e1f8537ccaf8\n",
      "\n",
      "\n",
      "2021-02-04T21:01:50Z The container already exists, stop and remove it before starting it.\n",
      "2021-02-04T21:01:50Z Stopping container bd97e264-18cf-4a2d-b471-6001a641299a exited with 1, Error response from daemon: No such container: bd97e264-18cf-4a2d-b471-6001a641299a\n",
      "\n",
      "\n",
      "2021-02-04T21:01:50Z Removing container bd97e264-18cf-4a2d-b471-6001a641299a exited with 1, Error: No such container: bd97e264-18cf-4a2d-b471-6001a641299a\n",
      "\n",
      "\n",
      "2c21d8552a5b1c9aac5af385d7a589c24a9bce0dd33ffb3f94da4affb9eb08a5\n",
      "2021/02/04 21:01:56 Starting App Insight Logger for task:  containerSetup\n",
      "2021/02/04 21:01:56 Version: 3.0.01485.0006 Branch: 2 Commit: a809e28\n",
      "2021/02/04 21:01:56 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/02/04 21:01:56 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/02/04 21:01:56 sshd inside container not required for job, skipping setup.\n",
      "2021/02/04 21:01:56 All App Insights Logs was send successfully\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d.txt\n",
      "===============================================================================================================\n",
      "[2021-02-04T21:01:31.457743] Entering job preparation.\n",
      "[2021-02-04T21:01:32.237772] Starting job preparation.\n",
      "[2021-02-04T21:01:32.237827] Extracting the control code.\n",
      "[2021-02-04T21:01:32.265380] fetching and extracting the control code on master node.\n",
      "[2021-02-04T21:01:32.265424] Starting extract_project.\n",
      "[2021-02-04T21:01:32.265472] Starting to extract zip file.\n",
      "[2021-02-04T21:01:33.131725] Finished extracting zip file.\n",
      "[2021-02-04T21:01:33.324085] Using urllib.request Python 3.0 or later\n",
      "[2021-02-04T21:01:33.324147] Start fetching snapshots.\n",
      "[2021-02-04T21:01:33.324186] Start fetching snapshot.\n",
      "[2021-02-04T21:01:33.324197] Retrieving project from snapshot: 595d64f0-f57b-4073-a08e-efa629308c8a\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 44\n",
      "[2021-02-04T21:01:33.636965] Finished fetching snapshot.\n",
      "[2021-02-04T21:01:33.638754] Start fetching snapshot.\n",
      "[2021-02-04T21:01:33.638800] Retrieving project from snapshot: a7f1f0d0-1132-4abe-90bd-ad706bec7189\n",
      "[2021-02-04T21:01:44.086088] Finished fetching snapshot.\n",
      "[2021-02-04T21:01:44.086129] Finished fetching snapshots.\n",
      "[2021-02-04T21:01:44.086334] Finished extract_project.\n",
      "[2021-02-04T21:01:44.097957] Finished fetching and extracting the control code.\n",
      "[2021-02-04T21:01:44.106436] Start run_history_prep.\n",
      "[2021-02-04T21:01:44.318314] Job preparation is complete.\n",
      "[2021-02-04T21:01:44.318385] Entering Data Context Managers in Sidecar\n",
      "[2021-02-04T21:01:44.320020] Running Sidecar prep cmd...\n",
      "[2021-02-04T21:01:44.380136] DEBUG azureml.sidecar.try_add_control_script_to_path: Adding ES Control Scripts to sys.path: /mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/azureml/bd97e264-18cf-4a2d-b471-6001a641299a-setup\n",
      "[2021-02-04T21:01:44.381253] DEBUG azureml.sidecar.TaskRegistry: Registering handler for task \"enter_contexts\"\n",
      "[2021-02-04T21:01:44.390701] DEBUG azureml.sidecar.TaskRegistry: Registering handler for task \"exit_contexts\"\n",
      "[2021-02-04T21:01:44.393721] DEBUG azureml.sidecar.set_run_wd: Changing working dir to: /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/azureml/bd97e264-18cf-4a2d-b471-6001a641299a\n",
      "[2021-02-04T21:01:44.394277] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/azureml/bd97e264-18cf-4a2d-b471-6001a641299a\n",
      "[2021-02-04T21:01:44.394793] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
      "[2021-02-04T21:01:44.395252] DEBUG azureml.sidecar.TaskRegistry.execute: Executing \"enter_contexts\"\n",
      "[2021-02-04T21:01:44.395757] DEBUG azureml.sidecar.TaskServerClient.__init__: Connecting to TaskServer at 127.0.0.1:51007\n",
      "[2021-02-04T21:01:44.396361] DEBUG azureml.sidecar.TaskRegistry.execute: Sending payload for \"enter_contexts\":\n",
      "{\"host_secret\": \"ed595fae-09f6-4731-9581-8479416803d6\", \"task\": \"enter_contexts\", \"caller_session_id\": \"951a280a-521e-4a86-b295-1134bd4b06ad\", \"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"], \"job_task_error_path\": \"/mnt/batch/tasks/workitems/fba38066-21d1-41d0-b619-a27c7312f762/job-1/bd97e264-18cf-4a2d-b_77375dc1-d3d5-46ca-a710-d2082fa3f25b/wd/runSpecialJobTask_error.json\"}\n",
      "[2021-02-04T21:01:47.887221] DEBUG azureml.sidecar.TaskRegistry.execute: Received response for \"enter_contexts\": {\"result\": \"success\"}\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.20.0 azureml-dataprep==2.7.3. Session id: 840ef773-81f9-4099-8a14-381c6091d09b. Run id: bd97e264-18cf-4a2d-b471-6001a641299a.\n",
      "Processing 'input_images'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'data/fowl_data/val')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"0985ad8a-0415-4c6d-a833-6c982dcb9ad6\",\n",
      "    \"name\": \"batch_scoring_input_images\",\n",
      "    \"version\": 1,\n",
      "    \"workspace\": \"Workspace.create(name='amlbriksews', subscription_id='bf088f59-f015-4332-bd36-54b988be7c90', resource_group='amlbrikserg')\"\n",
      "  }\n",
      "}\n",
      "Mounted input_images to $AZ_BATCHAI_JOB_MOUNT_ROOT/workspaceblobstore/data/fowl_data/val\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 1\n",
      "Sidecar adding paths_to_bind: ['/tmp/585ed646-9f67-454d-af1a-849a30ecb758', '/tmp/16783403-478d-4d50-bbc4-c61058cd76b4']\n",
      "Acquired lockfile /tmp/bd97e264-18cf-4a2d-b471-6001a641299a-datastore.lock to downloading input data references\n",
      "[2021-02-04T21:01:47.872627] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2021-02-04T21:01:47.874002] DEBUG azureml.sidecar.task.enter_contexts: Added Keys: ['AZUREML_SIDECAR_PATHS_TO_BIND']\n",
      "[2021-02-04T21:01:47.874374] DEBUG azureml.sidecar.task.enter_contexts: Updated Keys: ['INPUT_IMAGES', 'AZUREML_DATAREFERENCE_input_images', 'input_images']\n",
      "[2021-02-04T21:01:47.875472] DEBUG azureml.sidecar.task.enter_contexts: Persisted env vars changed by ContextManagers\n",
      "[2021-02-04T21:01:47.875983] DEBUG azureml.sidecar.task.enter_contexts: Get File Access Control List for /mnt/hostfs/tmp/585ed646-9f67-454d-af1a-849a30ecb758\n",
      "[2021-02-04T21:01:47.876430] DEBUG azureml.sidecar.task.enter_contexts: Get File Access Control List for /mnt/hostfs/tmp/16783403-478d-4d50-bbc4-c61058cd76b4\n",
      "[2021-02-04T21:01:49.323826] Ran Sidecar prep cmd.\n",
      "[2021-02-04T21:01:49.323874] Running Context Managers in Sidecar complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/02/04 21:01:58 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/02/04 21:01:58 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "[2021-02-04T21:01:59.440635] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.14.0', '--scoring_module_name', 'batch_score.py', '--mini_batch_size', '20', '--error_threshold', '1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'parallel_run_step.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/scores', '--process_count_per_node', '2', '--model_name', 'fowl-model', '--input_fds_0', 'input_images', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/data/fowl_data/val'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 75\n",
      "Entering Run History Context Manager.\n",
      "[2021-02-04T21:02:03.606466] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/azureml/bd97e264-18cf-4a2d-b471-6001a641299a\n",
      "[2021-02-04T21:02:03.607128] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.14.0', '--scoring_module_name', 'batch_score.py', '--mini_batch_size', '20', '--error_threshold', '1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'parallel_run_step.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/scores', '--process_count_per_node', '2', '--model_name', 'fowl-model', '--input_fds_0', 'input_images', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/data/fowl_data/val']\n",
      "[2021-02-04T21:02:03.615216] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.14.0', '--scoring_module_name', 'batch_score.py', '--mini_batch_size', '20', '--error_threshold', '1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'parallel_run_step.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/scores', '--process_count_per_node', '2', '--model_name', 'fowl-model', '--input_fds_0', 'input_images', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/data/fowl_data/val']\n",
      "\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d.txt\n",
      "===============================================================================================================\n",
      "[2021-02-04T21:02:55.201801] Entering job release\n",
      "[2021-02-04T21:02:56.059103] Starting job release\n",
      "[2021-02-04T21:02:56.064492] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 125\n",
      "[2021-02-04T21:02:56.064779] job release stage : upload_datastore starting...\n",
      "[2021-02-04T21:02:56.065040] job release stage : start importing azureml.history._tracking in run_history_release.[2021-02-04T21:02:56.067746] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-02-04T21:02:56.076151] job release stage : execute_job_release starting...\n",
      "\n",
      "[2021-02-04T21:02:56.077087] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-02-04T21:02:56.132399] Entering context manager injector.\n",
      "[2021-02-04T21:02:56.298802] job release stage : upload_datastore completed...\n",
      "[2021-02-04T21:02:56.364380] job release stage : execute_job_release completed...\n",
      "[2021-02-04T21:02:56.565472] job release stage : send_run_telemetry starting...\n",
      "[2021-02-04T21:02:57.399080] job release stage : send_run_telemetry completed...\n",
      "[2021-02-04T21:02:57.399537] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-02-04T21:02:57.399637] Running Sidecar release cmd...\n",
      "[2021-02-04T21:02:57.407269] DEBUG azureml.sidecar.try_add_control_script_to_path: Adding ES Control Scripts to sys.path: /mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/azureml/bd97e264-18cf-4a2d-b471-6001a641299a-setup\n",
      "[2021-02-04T21:02:57.409014] DEBUG azureml.sidecar.TaskRegistry: Registering handler for task \"enter_contexts\"\n",
      "[2021-02-04T21:02:57.416819] DEBUG azureml.sidecar.TaskRegistry: Registering handler for task \"exit_contexts\"\n",
      "[2021-02-04T21:02:57.420112] DEBUG azureml.sidecar.set_run_wd: Changing working dir to: /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/azureml/bd97e264-18cf-4a2d-b471-6001a641299a\n",
      "[2021-02-04T21:02:57.420683] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/amlbriksews/azureml/bd97e264-18cf-4a2d-b471-6001a641299a/mounts/workspaceblobstore/azureml/bd97e264-18cf-4a2d-b471-6001a641299a\n",
      "[2021-02-04T21:02:57.421307] DEBUG azureml.sidecar.TaskRegistry.execute: Executing \"exit_contexts\"\n",
      "[2021-02-04T21:02:57.421994] DEBUG azureml.sidecar.TaskServerClient.__init__: Connecting to TaskServer at 127.0.0.1:51007\n",
      "[2021-02-04T21:02:57.422494] DEBUG azureml.sidecar.TaskRegistry.execute: Sending payload for \"exit_contexts\":\n",
      "{\"host_secret\": \"ed595fae-09f6-4731-9581-8479416803d6\", \"task\": \"exit_contexts\", \"caller_session_id\": \"4c466860-f32f-403b-8e77-e0d417ea5507\", \"job_task_error_path\": \"/mnt/batch/tasks/workitems/fba38066-21d1-41d0-b619-a27c7312f762/job-1/bd97e264-18cf-4a2d-b_77375dc1-d3d5-46ca-a710-d2082fa3f25b/wd/runSpecialJobTask_error.json\"}\n",
      "[2021-02-04T21:02:57.662837] DEBUG azureml.sidecar.TaskRegistry.execute: Received response for \"exit_contexts\": {\"result\": \"success\"}\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Exit __exit__ of DatasetContextManager\n",
      "Removing absolute paths from host...\n",
      "[2021-02-04T21:02:57.653507] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-02-04T21:02:58.028174] Ran Sidecar release cmd.\n",
      "[2021-02-04T21:02:58.028306] Job release is complete\n",
      "\n",
      "StepRun(batchscoring-202102042022) Execution Summary\n",
      "=====================================================\n",
      "StepRun( batchscoring-202102042022 ) Status: Finished\n",
      "{'runId': 'bd97e264-18cf-4a2d-b471-6001a641299a', 'target': 'cpu-cluster', 'status': 'Completed', 'startTimeUtc': '2021-02-04T21:01:27.465775Z', 'endTimeUtc': '2021-02-04T21:03:11.680399Z', 'properties': {'ContentSnapshotId': '595d64f0-f57b-4073-a08e-efa629308c8a', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'c3b5010f-9ecf-482b-acf5-203ebea80a59', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'fa1ef946', 'azureml.pipelinerunid': '4e0c7105-28c2-4f1f-9898-bbd45e6b9332', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': '0985ad8a-0415-4c6d-a833-6c982dcb9ad6'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input_images', 'mechanism': 'Mount', 'pathOnCompute': 'e82dd41f-4717-49c5-8b83-93e29538bb29'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.14.0', '--scoring_module_name', 'batch_score.py', '--mini_batch_size', '20', '--error_threshold', '1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'parallel_run_step.txt', '--output', '$AZUREML_DATAREFERENCE_scores', '--process_count_per_node', '2', '--model_name', 'fowl-model', '--input_fds_0', 'input_images', '--input1', '$AZUREML_DATAREFERENCE_input_images_0'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpu-cluster', 'dataReferences': {'input_images_0': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'data/fowl_data/val', 'pathOnCompute': None, 'overwrite': False}, 'scores': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/bd97e264-18cf-4a2d-b471-6001a641299a/scores', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'input_images': {'dataLocation': {'dataset': {'id': '0985ad8a-0415-4c6d-a833-6c982dcb9ad6', 'name': None, 'version': '1'}, 'dataPath': None}, 'mechanism': 'Mount', 'environmentVariableName': 'input_images', 'pathOnCompute': 'e82dd41f-4717-49c5-8b83-93e29538bb29', 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'environment': {'name': 'pytorch-aml-env', 'version': '13', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge', 'pytorch'], 'dependencies': ['matplotlib=3.3.3', 'mlflow=1.13.1', 'python=3.7.1', 'pytorch::pytorch=1.7.0', 'pytorch::torchvision=0.8.1', 'scipy=1.6.0', 'tqdm=4.38.0', {'pip': ['azure-cli', 'azureml-contrib-functions', 'azureml-defaults', 'azureml-sdk', 'azureml-widgets', 'ipykernel', 'python-dotenv==0.15.0']}], 'name': 'azureml_6fbaaf797dfb760e2052930961d73e2a'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20201113.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': 'latest'}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': None, 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d.txt': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/azureml-logs/55_azureml-execution-tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d.txt?sv=2019-02-02&sr=b&sig=JP7fvPX3g2ph7oDNaZfg82KUE6y9r%2FIjrMlX6LlFH00%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'azureml-logs/65_job_prep-tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d.txt': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/azureml-logs/65_job_prep-tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d.txt?sv=2019-02-02&sr=b&sig=79eQObvCreAszI0cz%2BtdLClWwei37c6BD1kCxjDPl3I%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=y7kG5AcZYgk9YDyTeJmPAJkxV556YBrF6QdiOUw31ZQ%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'azureml-logs/75_job_post-tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d.txt': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/azureml-logs/75_job_post-tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d.txt?sv=2019-02-02&sr=b&sig=xFYA%2FHHV%2BVFDu7yDOV69I16eWAY8ugLSW4LTyOXp0qU%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'azureml-logs/process_info.json': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=2BT%2Fo%2FX2mZuThcoAncvc7UBjXsRkxs%2BS5GGgTGjnWwM%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'azureml-logs/process_status.json': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=65yRkjXEDP6l0sYgoK7sR9DUye7j3fX%2FimfcKv1ij9I%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/75_azureml.log': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/75_azureml.log?sv=2019-02-02&sr=b&sig=c7918d042N%2Fnd%2FEBcBCV2cgu0Niij3UhiZqIkW%2BH8Lc%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=TqryVUwhMU1atRTcp%2FwDKy5%2BsyPMRALULBAeNcIUoTQ%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=xK9WDKDhstUWC8tzPbzAya0Le%2BduGO5WnzHt%2FRGg3Aw%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/dataprep/engine_spans_840ef773-81f9-4099-8a14-381c6091d09b.jsonl': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/dataprep/engine_spans_840ef773-81f9-4099-8a14-381c6091d09b.jsonl?sv=2019-02-02&sr=b&sig=8SDp%2Fc%2Bbj0WB7cGy7sjnATFgZbkO3Up%2BUJmxnOmQWtw%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/dataprep/python_span_03216a25-e9ab-4cac-bea7-33ccf76a58e4.jsonl': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/dataprep/python_span_03216a25-e9ab-4cac-bea7-33ccf76a58e4.jsonl?sv=2019-02-02&sr=b&sig=XSP0ZhUuHaS7ED5XoPCfoIkV9h6U6woAby0UoNSdDz8%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/dataprep/python_span_840ef773-81f9-4099-8a14-381c6091d09b.jsonl': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/dataprep/python_span_840ef773-81f9-4099-8a14-381c6091d09b.jsonl?sv=2019-02-02&sr=b&sig=N%2B8AN8G4OHyTEGDq1deNesWfMdKZM%2FSbhYl09O5kehE%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/dataprep/python_span_92daa97d-cc91-488d-8826-337f4bfe53b5.jsonl': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/dataprep/python_span_92daa97d-cc91-488d-8826-337f4bfe53b5.jsonl?sv=2019-02-02&sr=b&sig=I987gWvCjky%2Be7dICUaXLm6IeM7QmFtBaUrfXIcZsqU%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/dataprep/python_span_b993d394-0dc0-477a-88ea-d074d176539f.jsonl': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/dataprep/python_span_b993d394-0dc0-477a-88ea-d074d176539f.jsonl?sv=2019-02-02&sr=b&sig=oCaMF%2B19dSCFX1I%2BpgtMkzInLvaalUCFz9DIM70MNoY%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=COTPfc45%2FjOVVbe8c7o120cHwQqnAAHjbHE0f0whuyg%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=AR4jxWo9oYXakQe8Pg1lkFzSGU3k64%2FGOs1qZSryfFY%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=KFXNZW%2Fk2gYjZ7Mh6TXpTMv5PJGed4h1KLQDvEKye2k%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/sidecar/tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d/all.log': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/sidecar/tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d/all.log?sv=2019-02-02&sr=b&sig=JKolGUTQNdsk9QQDdWR2WOk1J4ZDjANZy8HDsw9HVaQ%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/sidecar/tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d/task.enter_contexts.log': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/sidecar/tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=gzBaVAn2FcetOvfzvaox5qfAAN8HncRos%2BBhrnKDobk%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/sidecar/tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d/task.exit_contexts.log': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/sidecar/tvmps_f8848ddf4c5e6836dfff0726ab00d49e3ef5554b3c32ff215784e5f43d9f6106_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=9VB1NKOdcojx0tDHWncidvFxjphcWNVFNQqochSZxX0%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=ys%2B3CyC3%2BlIxucUyR174mIty8%2BSdTdH8SKc0hSyI4GQ%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.bd97e264-18cf-4a2d-b471-6001a641299a/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=iGX0zKiVxBQ%2Fg6ydL47ymS%2FKAlXa2AwWV74kzi6FjJM%3D&st=2021-02-04T20%3A52%3A59Z&se=2021-02-05T05%3A02%3A59Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '4e0c7105-28c2-4f1f-9898-bbd45e6b9332', 'status': 'Completed', 'startTimeUtc': '2021-02-04T21:01:01.440173Z', 'endTimeUtc': '2021-02-04T21:03:26.550102Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.4e0c7105-28c2-4f1f-9898-bbd45e6b9332/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=rmvIn1oZAY58BBWIBY7CW93jsKsbQDDkT4CaBWfbmS0%3D&st=2021-02-04T20%3A53%3A27Z&se=2021-02-05T05%3A03%3A27Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.4e0c7105-28c2-4f1f-9898-bbd45e6b9332/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=ChMsuqZUhgjStHTbrYATDXcY9cZbU5LxbwnSkGUFesU%3D&st=2021-02-04T20%3A53%3A27Z&se=2021-02-05T05%3A03%3A27Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlbriksews9265001959.blob.core.windows.net/azureml/ExperimentRun/dcid.4e0c7105-28c2-4f1f-9898-bbd45e6b9332/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=x1ijCbqXzZ%2FYSlnoiKTX%2BaEYnxGaN1TR%2FXTmRgFGOXs%3D&st=2021-02-04T20%3A53%3A27Z&se=2021-02-05T05%3A03%3A27Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait the run for completion and show output log to console\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download & Inspect Pipeline Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_run = pipeline_run.find_step_run(batch_score_step.name)[0]\n",
    "batch_output = batch_run.get_output_data(output_dir.name)\n",
    "\n",
    "target_dir = tempfile.mkdtemp()\n",
    "batch_output.download(local_path=target_dir)\n",
    "result_file = os.path.join(target_dir, batch_output.path_on_datastore, parallel_run_config.append_row_file_name)\n",
    "\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "# df.columns = [\"Filename\", \"Prediction\"]\n",
    "# print(\"Prediction has \", df.shape[0], \" rows\")\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  /mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...\n",
       "1  /mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...\n",
       "2  /mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...\n",
       "3  /mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...\n",
       "4  /mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...\n",
       "5  /mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...\n",
       "6  /mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...\n",
       "7  /mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...\n",
       "8  /mnt/batch/tasks/shared/LS_root/jobs/amlbrikse...\n",
       "9  /mnt/batch/tasks/shared/LS_root/jobs/amlbrikse..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publish the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publish the pipeline to create a REST endpoint that allows to rerun the pipeline from any HTTP library on any platform. The published pipeline can also be run from the AML workspace where different metdata such as run history and duration are tracked as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"fowl-pytorch-scoring\",\n",
    "    description=\"Batch scoring using fowl pytorch model\",\n",
    "    version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the pipeline from the REST endpoint, an OAuth2 Bearer-type authentication header is needed.\n",
    "\n",
    ". This example uses interactive authentication for illustration purposes, but for most production scenarios requiring automated or headless authentication, use service principle authentication as described in this notebook.\n",
    "\n",
    "Service principle authentication involves creating an App Registration in Azure Active Directory, generating a client secret, and then granting your service principal role access to your machine learning workspace. You then use the ServicePrincipalAuthentication class to manage your auth flow.\n",
    "\n",
    "Both InteractiveLoginAuthentication and ServicePrincipalAuthentication inherit from AbstractAuthentication, and in both cases you use the get_authentication_header() function in the same way to fetch the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "svc_pr_password = os.environ.get(\"AZUREML_PASSWORD\")\n",
    "\n",
    "svc_pr = ServicePrincipalAuthentication(\n",
    "    tenant_id=\"461e2020-109b-4c43-ad3f-eb9944f5dc44\",\n",
    "    service_principal_id=\"8a0b5ebf-55c7-4dfa-a49c-37b0acd9c3ce\",\n",
    "    service_principal_password=\"8k8Oq-.2mN_j.~~IJeR6kuhsv~DBou0BiO\")\n",
    "\n",
    "\n",
    "auth_header = svc_pr.get_authentication_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a POST Request to Trigger a Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the REST url from the endpoint property of the published pipeline object. You can also find the REST url in your workspace in the portal. Build an HTTP POST request to the endpoint, specifying your authentication header. Additionally, add a JSON payload object with the experiment name and the batch size parameter. As a reminder, the process_count_per_node is passed through to ParallelRunStep because you defined it is defined as a PipelineParameter object in the step configuration.\n",
    "\n",
    "Make the request to trigger the run. Access the Id key from the response dict to get the value of the run id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": \"Tutorial-Batch-Scoring\",\n",
    "                               \"ParameterAssignments\": {\"process_count_per_node\": 6}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    response.raise_for_status()\n",
    "except Exception:    \n",
    "    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n",
    "                    \"Response Code: {}\\n\"\n",
    "                    \"Headers: {}\\n\"\n",
    "                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n",
    "\n",
    "run_id = response.json().get('Id')\n",
    "print('Submitted pipeline run: ', run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[\"batch_scoring\"], run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detail information of the run\n",
    "published_pipeline_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-aml-env",
   "language": "python",
   "name": "pytorch-aml-env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
