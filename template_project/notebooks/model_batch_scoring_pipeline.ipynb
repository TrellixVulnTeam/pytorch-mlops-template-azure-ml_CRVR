{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Azure Machine Learning Pipelines for batch prediction\n",
    "In this tutorial, you use Azure Machine Learning service pipelines to run a batch scoring image classification job. The example job uses the pre-trained [Inception-V3](https://arxiv.org/abs/1512.00567) CNN (convolutional neural network) Tensorflow model to classify unlabeled images. Machine learning pipelines optimize your workflow with speed, portability, and reuse so you can focus on your expertise, machine learning, rather than on infrastructure and automation. After building and publishing a pipeline, you can configure a REST endpoint to enable triggering the pipeline from any HTTP library on any platform.\n",
    "\n",
    "In this tutorial, you learn the following tasks:\n",
    "\n",
    "> * Configure workspace and download sample data\n",
    "> * Create data objects to fetch and output data\n",
    "> * Download, prepare, and register the model to your workspace\n",
    "> * Provision compute targets and create a scoring script\n",
    "> * Use ParallelRunStep to do batch scoring\n",
    "> * Build, run, and publish a pipeline\n",
    "> * Enable a REST endpoint for the pipeline\n",
    "\n",
    "If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning service](https://aka.ms/AMLFree) today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "input_images = Dataset.File.from_files((batchscore_blob, \"batchscoring/images/\"))\n",
    "label_ds = Dataset.File.from_files((batchscore_blob, \"batchscoring/labels/\"))\n",
    "output_dir = PipelineData(name=\"scores\", datastore=def_data_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = input_images.register(workspace=ws, name=\"input_images\")\n",
    "label_ds = label_ds.register(workspace=ws, name=\"label_ds\", create_new_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and attach remote compute target\n",
    "\n",
    "Azure Machine Learning service pipelines cannot be run locally, and only run on cloud resources. Remote compute targets are reusable virtual compute environments where you run experiments and work-flows. Run the following code to create a GPU-enabled [`AmlCompute`](https://docs.microsoft.com/python/api/azureml-core/azureml.core.compute.amlcompute.amlcompute?view=azure-ml-py) target, and attach it to your workspace. See the [conceptual article](https://docs.microsoft.com/azure/machine-learning/service/concept-compute-target) for more information on compute targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "compute_name = \"gpu-cluster\"\n",
    "\n",
    "# checks to see if compute target already exists in workspace, else create it\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "except ComputeTargetException:\n",
    "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n",
    "                                                   vm_priority=\"lowpriority\", \n",
    "                                                   min_nodes=0, \n",
    "                                                   max_nodes=1)\n",
    "\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write a scoring script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the scoring, you create a batch scoring script `batch_scoring.py`, and write it to the current directory. The script takes a minibatch of input images, applies the classification model, and outputs the predictions to a results file.\n",
    "\n",
    "The script `batch_scoring.py` takes the following parameters, which get passed from the `ParallelRunStep` that you create later:\n",
    "\n",
    "- `--model_name`: the name of the model being used\n",
    "- `--labels_dir` : the directory path having the `labels.txt` file \n",
    "\n",
    "The pipelines infrastructure uses the `ArgumentParser` class to pass parameters into pipeline steps. For example, in the code below the first argument `--model_name` is given the property identifier `model_name`. In the `main()` function, this property is accessed using `Model.get_model_path(args.model_name)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"src/batch_scoring\"\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tensorflow.contrib.slim.python.slim.nets import inception_v3\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "image_size = 299\n",
    "num_channel = 3\n",
    "\n",
    "\n",
    "def get_class_label_dict(labels_dir):\n",
    "    label = []\n",
    "    labels_path = os.path.join(labels_dir, 'labels.txt')\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(labels_path).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label\n",
    "\n",
    "\n",
    "def init():\n",
    "    global g_tf_sess, probabilities, label_dict, input_images\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Start a tensorflow model serving\")\n",
    "    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n",
    "    parser.add_argument('--labels_dir', dest=\"labels_dir\", required=True)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    label_dict = get_class_label_dict(args.labels_dir)\n",
    "    classes_num = len(label_dict)\n",
    "\n",
    "    with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "        input_images = tf.placeholder(tf.float32, [1, image_size, image_size, num_channel])\n",
    "        logits, _ = inception_v3.inception_v3(input_images,\n",
    "                                              num_classes=classes_num,\n",
    "                                              is_training=False)\n",
    "        probabilities = tf.argmax(logits, 1)\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    g_tf_sess = tf.Session(config=config)\n",
    "    g_tf_sess.run(tf.global_variables_initializer())\n",
    "    g_tf_sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    model_path = Model.get_model_path(args.model_name)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(g_tf_sess, model_path)\n",
    "\n",
    "\n",
    "def file_to_tensor(file_path):\n",
    "    image_string = tf.read_file(file_path)\n",
    "    image = tf.image.decode_image(image_string, channels=3)\n",
    "\n",
    "    image.set_shape([None, None, None])\n",
    "    image = tf.image.resize_images(image, [image_size, image_size])\n",
    "    image = tf.divide(tf.subtract(image, [0]), [255])\n",
    "    image.set_shape([image_size, image_size, num_channel])\n",
    "    return image\n",
    "\n",
    "\n",
    "def run(mini_batch):\n",
    "    result_list = []\n",
    "    for file_path in mini_batch:\n",
    "        test_image = file_to_tensor(file_path)\n",
    "        out = g_tf_sess.run(test_image)\n",
    "        result = g_tf_sess.run(probabilities, feed_dict={input_images: [out]})\n",
    "        result_list.append(os.path.basename(file_path) + \": \" + label_dict[result[0]])\n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the first run in a given environment, Azure ML spends some time building the environment.\n",
    "# On the subsequent runs, Azure ML keeps track of changes and uses the existing environment, \n",
    "# resulting in faster run completion.\n",
    "\n",
    "# Create environment from yml file\n",
    "env = Environment.from_conda_specification(name=\"pytorch-aml-env\",\n",
    "                                           file_path=\"environment.yml\")\n",
    "\n",
    "# Attribute docker.enabled controls whether to use Docker container or host OS for execution.\n",
    "# This is only relevant for local execution as execution on AML Compute Cluster will always use Docker container.\n",
    "env.docker.enabled = True\n",
    "\n",
    "# Use Python dependencies from your Docker image (as opposed to from conda specification)\n",
    "# env.python.user_managed_dependencies=True\n",
    "\n",
    "# OPTION 1: Use mcr base image\n",
    "env.docker.base_image = \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20201113.v1\"\n",
    "\n",
    "# OPTION 2: Use custom base image\n",
    "#env.docker.base_image = \"myregistry.azurecr.io/mycustomimage:1.0\"\n",
    "#env.docker.base_image_registry.address = \"myregistry.azurecr.io\"\n",
    "#env.docker.base_image_registry.username = \"username\"\n",
    "#env.docker.base_image_registry.password = \"password\"\n",
    "\n",
    "# Create an environment variable.\n",
    "# This can be retrieved in the training script with os.environ.get(\"MESSAGE\").\n",
    "# env.environment_variables = {\"MESSAGE\": \"Hello from Azure Machine Learning\"}\n",
    "\n",
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the configuration to wrap the inference script\n",
    "Create the pipeline step using the script, environment configuration, and parameters. Specify the compute target you already attached to your workspace as the target of execution of the script. We will use PythonScriptStep to create the pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    environment=env,\n",
    "    entry_script=\"batch_scoring.py\",\n",
    "    source_directory=\"scripts\",\n",
    "    output_action=\"append_row\",\n",
    "    append_row_file_name=\"parallel_run_step.txt\",\n",
    "    mini_batch_size=\"20\",\n",
    "    error_threshold=1,\n",
    "    compute_target=compute_target,\n",
    "    process_count_per_node=2,\n",
    "    node_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the pipeline step\n",
    "\n",
    "A pipeline step is an object that encapsulates everything you need for running a pipeline including:\n",
    "\n",
    "* environment and dependency settings\n",
    "* the compute resource to run the pipeline on\n",
    "* input and output data, and any custom parameters\n",
    "* reference to a script or SDK-logic to run during the step\n",
    "\n",
    "There are multiple classes that inherit from the parent class [`PipelineStep`](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps.parallelrunstep?view=azure-ml-py) to assist with building a step using certain frameworks and stacks. In this example, you use the [`ParallelRunStep`](https://docs.microsoft.com/en-us/python/api/azureml-contrib-pipeline-steps/azureml.contrib.pipeline.steps.parallelrunstep?view=azure-ml-py) class to define your step logic using a scoring script. \n",
    "\n",
    "An object reference in the `outputs` array becomes available as an **input** for a subsequent pipeline step, for scenarios where there is more than one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunStep\n",
    "from datetime import datetime\n",
    "\n",
    "parallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "label_config = label_ds.as_named_input(\"labels_input\")\n",
    "\n",
    "batch_score_step = ParallelRunStep(\n",
    "    name=parallel_step_name,\n",
    "    inputs=[input_images.as_named_input(\"input_images\")],\n",
    "    output=output_dir,\n",
    "    arguments=[\"--model_name\", \"inception\",\n",
    "               \"--labels_dir\", label_config],\n",
    "    side_inputs=[label_config],\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    allow_reuse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a list of all classes for different step types, see the [steps package](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps?view=azure-ml-py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline\n",
    "\n",
    "Now you run the pipeline. First create a `Pipeline` object with your workspace reference and the pipeline step you created. The `steps` parameter is an array of steps, and in this case there is only one step for batch scoring. To build pipelines with multiple steps, you place the steps in order in this array.\n",
    "\n",
    "Next use the `Experiment.submit()` function to submit the pipeline for execution. You also specify the custom parameter `param_batch_size`. The `wait_for_completion` function will output logs during the pipeline build process, which allows you to see current progress.\n",
    "\n",
    "Note: The first pipeline run takes roughly **15 minutes**, as all dependencies must be downloaded, a Docker image is created, and the Python environment is provisioned/created. Running it again takes significantly less time as those resources are reused. However, total run time depends on the workload of your scripts and processes running in each pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[batch_score_step])\n",
    "pipeline_run = Experiment(ws, \"batch_scoring\").submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will output information of the pipeline run, including the link to the details page of portal.\n",
    "pipeline_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait the run for completion and show output log to console\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and review output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to download the output file created from the `batch_scoring.py` script, then explore the scoring results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "batch_run = pipeline_run.find_step_run(batch_score_step.name)[0]\n",
    "batch_output = batch_run.get_output_data(output_dir.name)\n",
    "\n",
    "target_dir = tempfile.mkdtemp()\n",
    "batch_output.download(local_path=target_dir)\n",
    "result_file = os.path.join(target_dir, batch_output.path_on_datastore, parallel_run_config.append_row_file_name)\n",
    "\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"Filename\", \"Prediction\"]\n",
    "print(\"Prediction has \", df.shape[0], \" rows\")\n",
    "df.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish and run from REST endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to publish the pipeline to your workspace. In your workspace in the portal, you can see metadata for the pipeline including run history and durations. You can also run the pipeline manually from the portal.\n",
    "\n",
    "Additionally, publishing the pipeline enables a REST endpoint to rerun the pipeline from any HTTP library on any platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"Inception_v3_scoring\", description=\"Batch scoring using Inception v3 model\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the pipeline from the REST endpoint, you first need an OAuth2 Bearer-type authentication header. This example uses interactive authentication for illustration purposes, but for most production scenarios requiring automated or headless authentication, use service principle authentication as [described in this notebook](https://aka.ms/pl-restep-auth).\n",
    "\n",
    "Service principle authentication involves creating an **App Registration** in **Azure Active Directory**, generating a client secret, and then granting your service principal **role access** to your machine learning workspace. You then use the [`ServicePrincipalAuthentication`](https://docs.microsoft.com/python/api/azureml-core/azureml.core.authentication.serviceprincipalauthentication?view=azure-ml-py) class to manage your auth flow. \n",
    "\n",
    "Both `InteractiveLoginAuthentication` and `ServicePrincipalAuthentication` inherit from `AbstractAuthentication`, and in both cases you use the `get_authentication_header()` function in the same way to fetch the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the REST url from the `endpoint` property of the published pipeline object. You can also find the REST url in your workspace in the portal. Build an HTTP POST request to the endpoint, specifying your authentication header. Additionally, add a JSON payload object with the experiment name and the batch size parameter. As a reminder, the `process_count_per_node` is passed through to `ParallelRunStep` because you defined it is defined as a `PipelineParameter` object in the step configuration.\n",
    "\n",
    "Make the request to trigger the run. Access the `Id` key from the response dict to get the value of the run id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": \"batch_scoring\",\n",
    "                               \"ParameterAssignments\": {\"process_count_per_node\": 6}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response.raise_for_status()\n",
    "except Exception:    \n",
    "    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n",
    "                    \"Response Code: {}\\n\"\n",
    "                    \"Headers: {}\\n\"\n",
    "                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n",
    "\n",
    "run_id = response.json().get('Id')\n",
    "print('Submitted pipeline run: ', run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the run id to monitor the status of the new run. This will take another 10-15 min to run and will look similar to the previous pipeline run, so if you don't need to see another pipeline run, you can skip watching the full output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[\"batch_scoring\"], run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detail information of the run\n",
    "published_pipeline_run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
