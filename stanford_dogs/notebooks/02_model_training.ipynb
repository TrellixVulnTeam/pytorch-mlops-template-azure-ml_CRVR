{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE OF CONTENTS:\n",
    "---\n",
    "* [Notebook Summary](#Notebook-Summary)\n",
    "* [Setup](#Setup)\n",
    "    * [Notebook Parameters](#Notebook-Parameters)\n",
    "    * [Connect to Workspace](#Connect-to-Workspace)\n",
    "* [Data](#Data)\n",
    "    * [Retrieve AML Dataset](#Retrieve-AML-Dataset)\n",
    "* [Compute Target](#Compute-Target)\n",
    "* [Training Artifacts](#Training-Artifacts)\n",
    "* [Training Environment](#Training-Environment)\n",
    "* [Experiment & Run Configuration](#Experiment-&-Run-Configuration)\n",
    "    * [Option 1: Normal Script Run](#Option-1:-Normal-Script-Run)\n",
    "    * [Option 2: Hyperdrive Run](#Option-2:-Hyperdrive-Run)\n",
    "* [Run Monitoring](#Run-Monitoring)\n",
    "* [Model Registration](#Model-Registration)\n",
    "    * [Model Download](#Model-Download)\n",
    "* [Resource Clean Up](#Resource-Clean-Up)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, a PyTorch model will be trained on the Stanford Dogs Dataset leveraging transfer learning by using a pretrained ResNext-50. A normal script run can be used for \"plain\" training of a single model on the Azure Machine Learning (AML) compute cluster. A hyperdrive run can be used to run parallel training with multiple hyperparameter configurations on multiple nodes of the AML compute cluster and is therefore useful for hyperparameter tuning.\n",
    "\n",
    "The compute cluster offers an autoscaling capability and will only be spinned up during an experiment. In general, model training should be done on the AML compute cluster for cost and performance reasons (powerful GPU clusters can be provisioned on demand and will shut down automatically)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append parent directory to sys path to be able to import created modules from src directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(\"\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically reload modules when changes are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml.core version: 1.20.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import azureml.core\n",
    "import shutil\n",
    "import torch\n",
    "from azureml.core import Dataset, Environment, Experiment, Keyvault, Model, ScriptRunConfig, Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.model import InferenceConfig \n",
    "from azureml.train.hyperdrive import BanditPolicy, HyperDriveConfig, PrimaryMetricGoal, RandomParameterSampling\n",
    "from azureml.train.hyperdrive import choice, uniform\n",
    "from azureml.widgets import RunDetails\n",
    "from torchvision import datasets\n",
    "\n",
    "print(f\"azureml.core version: {azureml.core.VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the dataset name\n",
    "dataset_name = \"stanford-dogs-dataset\"\n",
    "\n",
    "# Specify the name of the remote compute target (AML compute cluster)\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "# Specify the training environment name\n",
    "env_name = \"stanford-dogs-train-env\"\n",
    "\n",
    "# Specify the training experiment name\n",
    "experiment_name = \"stanford-dogs-classifier-train\"\n",
    "\n",
    "# Specify the src directory path\n",
    "src_dir = \"../src\"\n",
    "\n",
    "# Specify the model name\n",
    "model_name = \"dog-classification-model\"\n",
    "\n",
    "# Specify the model description\n",
    "model_description = \"PyTorch dog classification model trained on 120 dog breeds from the Stanford Dogs Dataset\"\n",
    "\n",
    "# Specify the remote run model path\n",
    "remote_model_path = \"outputs/dog_clf_model.pt\"\n",
    "\n",
    "# Specify the model tags\n",
    "model_tags = {\"type\": \"multiclass classification\"}\n",
    "\n",
    "# Specify the directory path for outputs\n",
    "outputs_dir = \"../outputs\"\n",
    "\n",
    "# Specify the local model path\n",
    "local_model_path = \"../outputs/dog_clf_model.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to the notebook parameters, the hyperparameters for the run configurations further down the notebook will have to be modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to connect and communicate with the AML workspace, a workspace object needs to be instantiated using the AML SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the AML workspace using interactive authentication\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve AML Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the dataset from the AML workspace. The dataset has been registered as part of the `01_dataset_setup` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.get_by_name(ws, name=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a remote compute target to run experiments on. The below code will first check whether a compute target with name **cluster_name** (specified as part of Notebook Parameters section) already exists and if it does, will retrieve it. Otherwise it will create a new compute cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 4, 'targetNodeCount': 4, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 4, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-03-14T07:57:15.668000+00:00', 'errors': None, 'creationTime': '2021-02-28T09:03:28.414676+00:00', 'modifiedTime': '2021-02-28T09:03:44.147067+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT2400S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(#vm_size=\"STANDARD_D2_V2\", # CPU\n",
    "                                                           vm_size='STANDARD_NC6', # GPU\n",
    "                                                           max_nodes=4,\n",
    "                                                           idle_seconds_before_scaledown=2400)\n",
    "    \n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use get_status() to get a detailed status for the current cluster\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A training script has been created in the `<PROJECT_ROOT>/src/training` folder. This script will be executed by the remote compute. The training script uses transfer learning to train a pretrained ResNext-50 model on the Stanford Dogs Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training script locally for 1 epoch for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.7.0\n",
      "--------------------\n",
      "CREATE DATALOADERS\n",
      "--------------------\n",
      "Dataloaders have been created successfully.\n",
      "--------------------\n",
      "START MODEL TRAINING\n",
      "--------------------\n",
      "Hyperparameter number of epochs: 1\n",
      "Hyperparameter batch size: 4\n",
      "Hyperparameter learning rate: 0.1\n",
      "Hyperparameter momentum: 0.9\n",
      "Hyperparameter number of frozen layers: 7\n",
      "Hyperparameter number of neurons fc layer: 512\n",
      "Hyperparameter dropout probability fc layer: 0\n",
      "Hyperparameter lr scheduler step size: 10\n",
      "Attempted to log scalar metric num_epochs:\n",
      "1\n",
      "Attempted to log scalar metric batch_size:\n",
      "4\n",
      "Attempted to log scalar metric lr:\n",
      "0.1\n",
      "Attempted to log scalar metric momentum:\n",
      "0.9\n",
      "Attempted to log scalar metric num_frozen_layers:\n",
      "7\n",
      "Attempted to log scalar metric num_neurons_fc_layer:\n",
      "512\n",
      "Attempted to log scalar metric dropout_prob_fc_layer:\n",
      "0\n",
      "Attempted to log scalar metric lr_scheduler_step_size:\n",
      "10\n",
      "--------------------\n",
      "Epoch 1/1\n",
      "--------------------\n",
      "Train Loss: 80.8739 Train Acc: 0.2336\n",
      "Attempted to log scalar metric train_loss:\n",
      "80.8739143223443\n",
      "Attempted to log scalar metric train_acc:\n",
      "0.23364583333333333\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} ../src/training/train.py --data_path ../data --num_epochs=1 --output_dir=\"../outputs\" --learning_rate 0.1 --momentum 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training environment that has been registered as part of the `00_environment_setup` notebook and use it for remote training on the AML compute cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment.get(workspace=ws, name=env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment & Run Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the training artifacts are prepared, a model can be trained on the remote compute cluster. You can take advantage of GPUs to cut down the training time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the experiment\n",
    "experiment = Experiment(workspace=ws, \n",
    "                        name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Normal Script Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variable to identify run type for logic later in the notebook\n",
    "run_type = \"script_run\"\n",
    "\n",
    "# Create the script run configuration\n",
    "src_config = ScriptRunConfig(source_directory=src_dir,\n",
    "                             script=\"training/train.py\",\n",
    "                             compute_target=compute_target,\n",
    "                             arguments=[\n",
    "                                 \"--data_path\", dataset.as_named_input(\"input\").as_mount(),\n",
    "                                 \"--num_epochs\", 36,\n",
    "                                 \"--output_dir\", \"outputs\",\n",
    "                                 \"--batch_size\", 8,\n",
    "                                 \"--learning_rate\", 0.01,\n",
    "                                 \"--momentum\", 0.9,\n",
    "                                 \"--num_frozen_layers\", 7,\n",
    "                                 \"--num_neurons_fc_layer\", 1024,\n",
    "                                 \"--dropout_prob_fc_layer\", 0.0,\n",
    "                                 \"--lr_scheduler_step_size\", 8])\n",
    "\n",
    "src_config.run_config.environment = env\n",
    "\n",
    "# Start the Script Run\n",
    "run = experiment.submit(src_config)\n",
    "\n",
    "# Tag the run trigger and model architecture\n",
    "run.tag(\"trigger\", \"jupyter_notebook\")\n",
    "run.tag(\"model_architecture\", \"transfer_learning_resnext-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Hyperdrive Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters can be tuned using AML's hyperdrive capability.\n",
    "\n",
    "The initial learning rate is tuned. The training script can contain a LR schedule to decay the learning rate every several epochs starting from that initial learning rate.\n",
    "\n",
    "Random sampling is used to try different configuration sets of hyperparameters to maximize the primary metric, the best validation accuracy (best_val_acc).\n",
    "\n",
    "An early termination policy is specified to early terminate poorly performing runs. The BanditPolicy is used, which will terminate any run that doesn't fall within the slack factor of the primary evaluation metric. In this template, this policy will be applied every epoch (since the best_val_acc metric is reported every epoch and evaluation_interval=1). The first policy evaluation will be delayed until after the first 20 epochs (delay_evaluation=20). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variable to identify run type for logic later in the notebook\n",
    "run_type = \"hyperdrive_run\"\n",
    "\n",
    "# Define the random parameter sampling\n",
    "param_sampling = RandomParameterSampling({\n",
    "    \"batch_size\": choice(8, 16),\n",
    "    \"learning_rate\": uniform(0.1, 0.3),\n",
    "    \"num_frozen_layers\": choice(6),\n",
    "    \"num_neurons_fc_layer\": choice(512, 768, 1024)})\n",
    "\n",
    "# Check https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters#bandit-policy\n",
    "# for details on BanditPolicy\n",
    "early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=20)\n",
    "\n",
    "# Create the script run configuration\n",
    "src_config = ScriptRunConfig(source_directory=src_dir,\n",
    "                             script=\"training/train.py\",\n",
    "                             compute_target=compute_target,\n",
    "                             arguments=[\n",
    "                                 \"--data_path\", dataset.as_named_input(\"input\").as_mount(),\n",
    "                                 \"--num_epochs\", 60,\n",
    "                                 \"--output_dir\", \"outputs\",\n",
    "                                 \"--batch_size\", 16,\n",
    "                                 \"--learning_rate\", 0.1,\n",
    "                                 \"--momentum\", 0.9,\n",
    "                                 \"--num_frozen_layers\", 7,\n",
    "                                 \"--num_neurons_fc_layer\", 1024,\n",
    "                                 \"--dropout_prob_fc_layer\", 0.0,\n",
    "                                 \"--lr_scheduler_step_size\", 7])\n",
    "\n",
    "src_config.run_config.environment = env\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(run_config=src_config,\n",
    "                                     hyperparameter_sampling=param_sampling, \n",
    "                                     policy=early_termination_policy,\n",
    "                                     primary_metric_name=\"best_val_acc\",\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=8,\n",
    "                                     max_concurrent_runs=4)\n",
    "\n",
    "# Start the Hyperdrive Run\n",
    "run = experiment.submit(hyperdrive_config)\n",
    "\n",
    "# Tag the run trigger and model architecture\n",
    "run.tag(\"trigger\", \"jupyter_notebook\")\n",
    "run.tag(\"model_architecture\", \"transfer_learning_resnext-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get portal URL\n",
    "run.get_portal_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve best child run\n",
    "if run_type == \"hyperdrive_run\":\n",
    "    best_child_run = run.get_best_run_by_primary_metric()\n",
    "elif run_type == \"script_run\":\n",
    "    best_child_run = run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check run metrics, details and file names\n",
    "best_child_run_metrics = best_child_run.get_metrics()\n",
    "best_child_run_details = best_child_run.get_details()\n",
    "best_child_run_file_names = best_child_run.get_file_names()\n",
    "\n",
    "\n",
    "print(best_child_run_metrics)\n",
    "print(\"==========================\")\n",
    "print(best_child_run_details)\n",
    "print(\"==========================\")\n",
    "print(best_child_run_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Run is:\")\n",
    "print(f\"Validation accuracy: {best_child_run_metrics['best_val_acc'][-1]}\")\n",
    "print(f\"Learning rate: {best_child_run_metrics['lr']}\")\n",
    "print(f\"Momentum: {best_child_run_metrics['momentum']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the model to the AML workspace for subsequent deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_child_run.register_model(model_name=model_name,\n",
    "                                      description=model_description,\n",
    "                                      model_path=remote_model_path,\n",
    "                                      tags=model_tags,\n",
    "                                      properties={\"val_acc\": best_child_run_metrics[\"best_val_acc\"][-1]},\n",
    "                                      model_framework=Model.Framework.PYTORCH,\n",
    "                                      model_framework_version=torch.__version__)\n",
    "\n",
    "print(model.name, model.id, model.version, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the input dataset to the registered model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_dataset_references([(\"input dataset\", dataset)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If required, the model can be downloaded as follows (e.g. for local testing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_model=False\n",
    "\n",
    "if download_model:\n",
    "    \n",
    "    # Create directory\n",
    "    outputs_folder = os.path.join(os.getcwd(), outputs_dir)\n",
    "    os.makedirs(outputs_folder, exist_ok=True)\n",
    "    print(f\"Outputs folder {outputs_folder} has been created.\")\n",
    "    \n",
    "    # Download model artifact\n",
    "    best_child_run.download_file(name=model_path, output_file_path=local_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target.delete()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "samkemp"
   }
  ],
  "categories": [
   "tutorials",
   "get-started-day1"
  ],
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "stanford-dogs-dev-env",
   "language": "python",
   "name": "stanford-dogs-dev-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "notice": "Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
